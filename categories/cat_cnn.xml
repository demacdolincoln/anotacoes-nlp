<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anotações sobre NLP (Posts sobre cnn)</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/</link><description></description><atom:link href="http://demacdolincoln.github.io/anotacoes-nlp/posts/categories/cat_cnn.xml" rel="self" type="application/rss+xml"></atom:link><language>pt_br</language><copyright>Contents © 2018 &lt;a href="mailto:demacdolincoln@gmail.com"&gt;Lincoln de Macêdo&lt;/a&gt; </copyright><lastBuildDate>Tue, 25 Dec 2018 16:11:08 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Classificação 2: CNN</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-2-cnn/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Como falado &lt;cite&gt;anteriormente &amp;lt;link://filename/posts/classificacao-1.rst&amp;gt;_&lt;/cite&gt;, classificar um texto é algo que vai além do vocabulário ainda que a gente utilize o word2vec ou o glove, e como a ordem das palavras importa muito, vamos dar aqui o 1º passo neste sentido, vamos ver como funciona uma rede neural convolucional (CNN) aplicada à classificação de textos.&lt;/p&gt;
&lt;p&gt;Habitualmente elas são usadas essencialmente em processamento de imagens, a idéia é bastante simples: ter uma matriz maior e calcular uma matriz menor equivalente, neste processo há perda de dados e portanto é irreversível, porém tem se demonstrado muito útil em muitos casos.&lt;/p&gt;
&lt;div class="section" id="implementacao"&gt;
&lt;h2&gt;Implementação:&lt;/h2&gt;
&lt;p&gt;O primeiro passo é transformar um texto numa matriz, para isso vamos recordar o que temos:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;texto ~&amp;gt; sequência de ids de palavras&lt;/li&gt;
&lt;li&gt;skip-gram, cbow, glove, etc. ~&amp;gt; representação cartesiana de palavras segundo o sentido compreendido pelo seu uso&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Diante disso se torna meio lógico fazer uma matriz no formato &lt;cite&gt;words x embedding dims&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;Um dos problemas dessa abordagem é que frases tem tamanhos variáveis enquanto a matriz de entrada na camada convolucional da CNN precisa ter tamanho fixo, então temos de lidar sempre com o pior caso, frases grandes, e preencher o espaço restante das frases menores com zeros, isso acaba nos obrigando ter um custo computacional extra já que teremos muitos espaços em branco só para que sempre tenhamos matrizes do mesmo tamanho.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leituras-recomendadas"&gt;
&lt;h2&gt;Leituras recomendadas:&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/abs/1408.5882"&gt;https://arxiv.org/abs/1408.5882&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>classificação</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-2-cnn/</guid><pubDate>Tue, 25 Dec 2018 08:17:55 GMT</pubDate></item></channel></rss>