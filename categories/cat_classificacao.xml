<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anotações sobre NLP (Posts sobre classificação)</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/</link><description></description><atom:link href="http://demacdolincoln.github.io/anotacoes-nlp/posts/categories/cat_classificacao.xml" rel="self" type="application/rss+xml"></atom:link><language>pt_br</language><copyright>Contents © 2018 &lt;a href="mailto:demacdolincoln@gmail.com"&gt;Lincoln de Macêdo&lt;/a&gt; </copyright><lastBuildDate>Tue, 25 Dec 2018 16:18:58 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Classificação 1</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;O problema fundamental da classificação de textos reside no fato da dificuldade de representar o texto a nível numérico, ainda que o word2vec, o glove, o seq2seq sejam realmente úteis assim como vários outros algoritmos que não incluí aqui mas que são facilmente encontrados em buscas no google, eles por si só não conseguem ir além da representação semântica ou de alguma outra lógica sobre as palavras, tanto para gerar textos quanto para classificá-los precisamos do auxílio de outros algoritmos. O objetivo desta anotação é identificar os desafions inerentes a esta tarefa.&lt;/p&gt;
&lt;div class="section" id="apenas-vocabulario"&gt;
&lt;h2&gt;Apenas vocabulário&lt;/h2&gt;
&lt;p&gt;Esse seria o caminho mais óbvio, tendo em vista que temos uma representação espacial da disposição das palavras num hiperplano, então faz sentido imaginar que textos sobre diferentes assuntos necessariamente tem diferentes vocabulários. Façamos um teste:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;peguei 2 textos da wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="loweralpha simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.wikipedia.org/wiki/Lutefisk"&gt;Lutefisk&lt;/a&gt; - um prato da culinária norueguesa&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.wikipedia.org/wiki/Erhu"&gt;Erhu&lt;/a&gt; - um instrumento tradicional chinês&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;fiz o pré-processamento das palavras como já descrito em outro post, ficando apenas com o vocabulário&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;peguei as posições correspondentes a cada palavra no skip-gram já treinado&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;reduzi as dimensões e plotei o gráfico&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="/images/classificacao_1_scatter_voc.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classificacao_1_scatter_voc.png"&gt;
&lt;p&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/#id1"&gt;&lt;span class="problematic" id="id2"&gt;**&lt;/span&gt;&lt;/a&gt;explicando as cores:&lt;/p&gt;
&lt;div class="system-message" id="id1"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;tt class="docutils"&gt;&amp;lt;string&amp;gt;&lt;/tt&gt;, line 19); &lt;em&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
Inline strong start-string without end-string.&lt;/div&gt;
&lt;!-- vermelho: vocabulário do texto 1 --&gt;
&lt;!-- ciano: vocabulário do texto 2 --&gt;
&lt;!-- branco: vocabulário em comum a ambos --&gt;
&lt;p&gt;Como é possível perceber acima, não identificamos um nível de separação consistente entre os vocabulários, olhando a densidade de concentração do vocabulário nos dois textos, descartando as palavras em comum, temos a imagem abaixo:&lt;/p&gt;
&lt;img alt="/images/classificação_1_kde_voc.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classifica%C3%A7%C3%A3o_1_kde_voc.png"&gt;
&lt;p&gt;Os centros estão muito próximos, ou seja, mesmo identificando as regiões mais densas nos vocabulários, ao tentar usar esta região como métrica, a similaridade de sentido entre os termos para o texto 1 e para o texto 2 continuam muito próximas tornando essa estratégia bem ineficaz.&lt;/p&gt;
&lt;p&gt;A solução está na compreensão que um texto não são apenas palavras soltas, mas o sentifo extrapola a simples junção de palavras, então a ordem do que está escrito importa, a disposição das palavras no texto importa muito.&lt;/p&gt;
&lt;p&gt;Nas próximas anotações abordarei sobre o uso de redes convolucionais e redes neurais recorrentes, diferentes formas de tentar burlar as dificuldades aqui apresentadas.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/</guid><pubDate>Mon, 24 Dec 2018 05:12:26 GMT</pubDate></item></channel></rss>