<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anotações sobre NLP (Posts sobre word2vec)</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/</link><description></description><atom:link href="http://demacdolincoln.github.io/anotacoes-nlp/posts/categories/word2vec.xml" rel="self" type="application/rss+xml"></atom:link><language>pt_br</language><copyright>Contents © 2018 &lt;a href="mailto:demacdolincoln@gmail.com"&gt;Lincoln de Macêdo&lt;/a&gt; </copyright><lastBuildDate>Tue, 25 Dec 2018 08:22:22 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>word2vec 3: skip-gram</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-3-skip-gram/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Como já dito antes, o skip-gram faz um treinamento meio que ao contrário do cbow, no treinamento a rede neural recebe as palavras centrais para tentar prever as palavras de contexto e assim ajusta os pesos das camadas da rede neural aproximando valores para palavras semelhantes no hiperplano.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;text_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-8"&gt;&lt;/a&gt;           &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-9"&gt;&lt;/a&gt;       &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_size&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-12"&gt;&lt;/a&gt;    &lt;span class="n"&gt;center_word_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;context_word_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;pair_ids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;center_word_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;context_word_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_d7a929b15f6a469cada19f39350511fd-16"&gt;&lt;/a&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;A única diferença do código acima para criar os pares de ids está na ordem: primeiro a palavra central e depois a palavra de contexto:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;central&lt;/th&gt;
&lt;th class="head"&gt;contexto&lt;/th&gt;
&lt;th class="head"&gt;central&lt;/th&gt;
&lt;th class="head"&gt;contexto&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;604&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;máquina&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;302&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;td&gt;computação&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;604&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;td&gt;máquina&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;277&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;td&gt;papel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;604&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;td&gt;máquina&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;277&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;td&gt;papel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;409&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;td&gt;importante&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;277&lt;/td&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;papel&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;277&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;papel&lt;/td&gt;
&lt;td&gt;desempenhando&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;O modelo da rede neural não se difere muito da usada no cbow, a única diferença fica por conta do tamanho da entrada da primeira função linear, já que passaremos 1 id por vez e não 4 como no cbow.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CBOW&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-3"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CBOW&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-7"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# única diferença aqui&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-8"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-10"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_softmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LogSoftmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-19"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-20"&gt;&lt;/a&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-21"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_word_emb&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word_id&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-22"&gt;&lt;/a&gt;        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LongTensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_bfb053bc8fe84bd6bc826f8dc55d430a-23"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;De modo geral o nível de erro (ou perda, nunca sei ao certo como traduzir "loss" neste contexto) no skip-gram é maior que no cbow, mas repito que o importante é que esteja havendo um aprendizado e não que a rede neural se adapte ao ponto de prever todas as palavras relacionadas ainda que ocasionalmente isso ocorra, para nós interessa o seguinte movimento: numa época a rede neural elevar os valores das palavras próximas na saída e afastar as mais distantes, assim naturalmente ela vai aprendendo a agrupar palavras em regiões de um hiperplano aproximando ou afastando de acordo com o modo como as palavras são usadas, tendendo a manter um distanciamento relacionado ao seu valor semântico.&lt;/p&gt;
&lt;img alt="/images/word2vec-skipgram-loss.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-skipgram-loss.png"&gt;
&lt;p&gt;Reduzindo as dimensões para visualizar a distribuição...&lt;/p&gt;
&lt;img alt="/images/word2vec-skipgram-1.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-skipgram-1.png" style="width: 500px;"&gt;
&lt;p&gt;Logicamente dessa forma como implementei, o custo/perda/loss é mais alto que na implementação feita do cbow, afinal vamos aos poucos ajustando 4 resultados possíveis para cada termo. Neste exemplo aumentei a quantidade de épocas para 2500 e ainda assim ficou imensamente distante do resultado da implementação do cbow neste aspecto, porém a relação entre as palavras se mostrou um pouco melhor ainda que longe do ideal.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;rank sim cos&lt;/th&gt;
&lt;th class="head"&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;
&lt;/li&gt;&lt;/ul&gt;
&lt;/th&gt;
&lt;th class="head"&gt;rank dist eucl&lt;/th&gt;
&lt;th class="head"&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;
&lt;/li&gt;&lt;/ul&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;muitos&lt;/td&gt;
&lt;td&gt;0.14544&lt;/td&gt;
&lt;td&gt;muitos&lt;/td&gt;
&lt;td&gt;0.07375&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;poderia&lt;/td&gt;
&lt;td&gt;0.26087&lt;/td&gt;
&lt;td&gt;code&lt;/td&gt;
&lt;td&gt;0.08692&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ceruzzi&lt;/td&gt;
&lt;td&gt;0.28141&lt;/td&gt;
&lt;td&gt;ceruzzi&lt;/td&gt;
&lt;td&gt;0.08939&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;code&lt;/td&gt;
&lt;td&gt;0.28206&lt;/td&gt;
&lt;td&gt;condados&lt;/td&gt;
&lt;td&gt;0.09595&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;britânica&lt;/td&gt;
&lt;td&gt;0.28430&lt;/td&gt;
&lt;td&gt;mortem&lt;/td&gt;
&lt;td&gt;0.09709&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mortem&lt;/td&gt;
&lt;td&gt;0.33544&lt;/td&gt;
&lt;td&gt;atos&lt;/td&gt;
&lt;td&gt;0.10284&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;condenado&lt;/td&gt;
&lt;td&gt;0.33660&lt;/td&gt;
&lt;td&gt;teórica&lt;/td&gt;
&lt;td&gt;0.10357&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;comerciantes&lt;/td&gt;
&lt;td&gt;0.33929&lt;/td&gt;
&lt;td&gt;condenado&lt;/td&gt;
&lt;td&gt;0.10376&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;cabeceira&lt;/td&gt;
&lt;td&gt;0.34548&lt;/td&gt;
&lt;td&gt;rápido&lt;/td&gt;
&lt;td&gt;0.10433&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;condados&lt;/td&gt;
&lt;td&gt;0.36041&lt;/td&gt;
&lt;td&gt;prazer&lt;/td&gt;
&lt;td&gt;0.10648&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;img alt="/images/word2vec-skipgram-rank.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-skipgram-rank.png"&gt;
&lt;p&gt;Só lembrando que segui o mesmo padrão de cores:&lt;/p&gt;
&lt;table class="docutils field-list" frame="void" rules="none"&gt;
&lt;col class="field-name"&gt;
&lt;col class="field-body"&gt;
&lt;tbody valign="top"&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;amarelo:&lt;/th&gt;&lt;td class="field-body"&gt;Palavra escolhida&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;vermelho:&lt;/th&gt;&lt;td class="field-body"&gt;Termos mais próximos pela similaridade de cossenos&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;azul:&lt;/th&gt;&lt;td class="field-body"&gt;Termos mais próximos pela distância euclidiana&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;roxo:&lt;/th&gt;&lt;td class="field-body"&gt;Termos que ambas as métricas concordam&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="notebook"&gt;
    &lt;a class="notebook-link" href="http://nbviewer.jupyter.org/github/demacdolincoln/anotacoes-nlp/blob/src/files/word2vec-3-skipgram.ipynb"&gt;code&lt;/a&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>word2vec</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-3-skip-gram/</guid><pubDate>Fri, 07 Dec 2018 04:43:36 GMT</pubDate></item><item><title>Word2Vec 2: CBOW</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Na anotação anterior vimos de forma mais ou menos prática o sentido da coisa, implementamos o Word2Vec com o objetivo de identificar a proximidade semântica entre palavras com base no uso em textos, este post é fundamentalmente teórico e a implementação do cbow aqui demonstrada está muito longe de ser algo pronto para produção, é apenas um exemplo que tenta ser didático.&lt;/p&gt;
&lt;div class="section" id="preparacao-dos-dados"&gt;
&lt;h2&gt;preparação dos dados&lt;/h2&gt;
&lt;p&gt;Como nosso objetivo é fazer com que uma rede neural receba as palavras de contexto e indique a palavra central, e na anotação anterior fiz uma pequena observação dizendo que sempre teremos $2w$ palavras de contexto para cada palavra central e assim faremos, vamos modificar um pouco o código que cria os pares do word2vec:&lt;/p&gt;
&lt;table class="codetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-1"&gt; 1&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-2"&gt; 2&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-3"&gt; 3&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-4"&gt; 4&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-5"&gt; 5&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-6"&gt; 6&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-7"&gt; 7&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-8"&gt; 8&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-9"&gt; 9&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-10"&gt;10&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-11"&gt;11&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-12"&gt;12&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_b681d05195e54117935d1c2ab3132375-13"&gt;13&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code python"&gt;&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;text_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_size&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;center_word_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-11"&gt;&lt;/a&gt;    &lt;span class="n"&gt;context_words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_b681d05195e54117935d1c2ab3132375-13"&gt;&lt;/a&gt;    &lt;span class="n"&gt;pair_ids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;context_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;center_word_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Assim feito, teremos algo como:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;contexto&lt;/th&gt;
&lt;th class="head"&gt;central&lt;/th&gt;
&lt;th class="head"&gt;contexto&lt;/th&gt;
&lt;th class="head"&gt;central&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;[155, 77, 577, 495]&lt;/td&gt;
&lt;td&gt;544&lt;/td&gt;
&lt;td&gt;['armazenado', 'ace', 'turing', 'interessou']&lt;/td&gt;
&lt;td&gt;posteriormente&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[77, 544, 495, 233]&lt;/td&gt;
&lt;td&gt;577&lt;/td&gt;
&lt;td&gt;['ace', 'posteriormente', 'interessou', 'química']&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[544, 577, 233, 308]&lt;/td&gt;
&lt;td&gt;495&lt;/td&gt;
&lt;td&gt;['posteriormente', 'turing', 'química', 'escreveu']&lt;/td&gt;
&lt;td&gt;interessou&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[577, 495, 308, 446]&lt;/td&gt;
&lt;td&gt;233&lt;/td&gt;
&lt;td&gt;['turing', 'interessou', 'escreveu', 'artigo']&lt;/td&gt;
&lt;td&gt;química&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[495, 233, 446, 537]&lt;/td&gt;
&lt;td&gt;308&lt;/td&gt;
&lt;td&gt;['interessou', 'química', 'artigo', 'sobre']&lt;/td&gt;
&lt;td&gt;escreveu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[233, 308, 537, 323]&lt;/td&gt;
&lt;td&gt;446&lt;/td&gt;
&lt;td&gt;['química', 'escreveu', 'sobre', 'base']&lt;/td&gt;
&lt;td&gt;artigo&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[308, 446, 323, 233]&lt;/td&gt;
&lt;td&gt;537&lt;/td&gt;
&lt;td&gt;['escreveu', 'artigo', 'base', 'química']&lt;/td&gt;
&lt;td&gt;sobre&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[446, 537, 233, 504]&lt;/td&gt;
&lt;td&gt;323&lt;/td&gt;
&lt;td&gt;['artigo', 'sobre', 'química', 'morfogênese']&lt;/td&gt;
&lt;td&gt;base&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[537, 323, 504, 506]&lt;/td&gt;
&lt;td&gt;233&lt;/td&gt;
&lt;td&gt;['sobre', 'base', 'morfogênese', 'previu']&lt;/td&gt;
&lt;td&gt;química&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[323, 233, 506, 492]&lt;/td&gt;
&lt;td&gt;504&lt;/td&gt;
&lt;td&gt;['base', 'química', 'previu', 'reações']&lt;/td&gt;
&lt;td&gt;morfogênese&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[233, 504, 492, 8]&lt;/td&gt;
&lt;td&gt;506&lt;/td&gt;
&lt;td&gt;['química', 'morfogênese', 'reações', 'químicas']&lt;/td&gt;
&lt;td&gt;previu&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="a-rede-neural"&gt;
&lt;h2&gt;A rede neural&lt;/h2&gt;
&lt;p&gt;O que importa na rede neural neste método e no skip-gram é a camada &lt;em&gt;Embedding&lt;/em&gt;&lt;/p&gt;
&lt;table class="codetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-1"&gt; 1&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-2"&gt; 2&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-3"&gt; 3&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-4"&gt; 4&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-5"&gt; 5&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-6"&gt; 6&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-7"&gt; 7&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-8"&gt; 8&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-9"&gt; 9&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-10"&gt;10&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-11"&gt;11&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-12"&gt;12&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-13"&gt;13&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-14"&gt;14&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-15"&gt;15&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-16"&gt;16&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-17"&gt;17&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-18"&gt;18&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-19"&gt;19&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-20"&gt;20&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-21"&gt;21&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-22"&gt;22&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/#rest_code_711fe1ba88cc4cbaafb806418ef3610c-23"&gt;23&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code python"&gt;&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CBOW&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;context_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-3"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CBOW&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-7"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;emb_size&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;context_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-8"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-10"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_softmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LogSoftmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-19"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-20"&gt;&lt;/a&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-21"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_word_emb&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word_id&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-22"&gt;&lt;/a&gt;        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LongTensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_711fe1ba88cc4cbaafb806418ef3610c-23"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;O treinamento será demorado, afinal como já dito, este não é um código para produção, é apenas um código didático, então enquanto ocorre o treinamento, não é má idéia ir tomar um chá e caminhar um pouco.&lt;/p&gt;
&lt;p&gt;Algo que preciso ressaltar aqui é que predizer a palavra central corretamente não importa tanto, o importante é que esteja ocorrendo o aprendizado já queo que nos interessa é que os valores da camada incorporada se aproximem em palavras próximas e se distanciem para palavras distantes, então é de se esperar um gráfico horrível mostrando a evolução da perda.&lt;/p&gt;
&lt;img alt="/images/word2vec-cbow-loss.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-cbow-loss.png"&gt;
&lt;p&gt;Para visualizar a distribuição das palavras num plano cartesiano, faremos o mesmo que com o Gensim, usaremos a implementação do PCA disponível no slearn.&lt;/p&gt;
&lt;img alt="/images/word2vec-cbow-1.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-cbow-1.png"&gt;
&lt;p&gt;Observando a similaridade, que não é lá tão boa neste caso devido a total falta de otimização em tudo no código:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;col width="25%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;rank sim cos&lt;/th&gt;
&lt;th class="head"&gt; &lt;/th&gt;
&lt;th class="head"&gt;rank dist eucl&lt;/th&gt;
&lt;th class="head"&gt; &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;novas&lt;/td&gt;
&lt;td&gt;0.28059&lt;/td&gt;
&lt;td&gt;novas&lt;/td&gt;
&lt;td&gt;0.09326&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;equivalia&lt;/td&gt;
&lt;td&gt;0.31309&lt;/td&gt;
&lt;td&gt;polonesa&lt;/td&gt;
&lt;td&gt;0.09989&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pioneiro&lt;/td&gt;
&lt;td&gt;0.31798&lt;/td&gt;
&lt;td&gt;neve&lt;/td&gt;
&lt;td&gt;0.10029&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;afirma&lt;/td&gt;
&lt;td&gt;0.32445&lt;/td&gt;
&lt;td&gt;andrew&lt;/td&gt;
&lt;td&gt;0.10191&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;neve&lt;/td&gt;
&lt;td&gt;0.33447&lt;/td&gt;
&lt;td&gt;pioneiro&lt;/td&gt;
&lt;td&gt;0.10310&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;polonesa&lt;/td&gt;
&lt;td&gt;0.33585&lt;/td&gt;
&lt;td&gt;afirma&lt;/td&gt;
&lt;td&gt;0.10484&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;massachusetts&lt;/td&gt;
&lt;td&gt;0.34675&lt;/td&gt;
&lt;td&gt;conduzida&lt;/td&gt;
&lt;td&gt;0.10508&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;conduzida&lt;/td&gt;
&lt;td&gt;0.34768&lt;/td&gt;
&lt;td&gt;bombas&lt;/td&gt;
&lt;td&gt;0.10641&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;andrew&lt;/td&gt;
&lt;td&gt;0.35143&lt;/td&gt;
&lt;td&gt;manipular&lt;/td&gt;
&lt;td&gt;0.10718&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hastings&lt;/td&gt;
&lt;td&gt;0.35665&lt;/td&gt;
&lt;td&gt;homossexuais&lt;/td&gt;
&lt;td&gt;0.11074&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Observando onde cada termo está com as dimensões da camada incorporada da rede neural reduzida a 2d temos:&lt;/p&gt;
&lt;img alt="/images/word2vec-cbow-rank.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-cbow-rank.png"&gt;
&lt;p&gt;É compreensível ver estas distâncias tão em desarcodo pelo fato das distorções da redução de dimensões, de 10 para 2.&lt;/p&gt;
&lt;div class="notebook"&gt;
    &lt;a class="notebook-link" href="http://nbviewer.jupyter.org/github/demacdolincoln/anotacoes-nlp/blob/src/files/word2vec-2-cbow.ipynb"&gt;code&lt;/a&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>word2vec</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-2-cbow/</guid><pubDate>Fri, 07 Dec 2018 03:23:12 GMT</pubDate></item><item><title>Word2Vec 1: Introdução</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-1-introducao/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;O Word2Vec parte de uma idéia muito simples e até certo ponto bastante lógica: relacionar uma palavra com as que estão em sua volta num texto. A partir desse conceito tão básico o Word2Vec acaba sendo uma base para outros algoritmos e não necessariamente um fim em si, a partir dele vamos implementar o cbow e o skip-gram nas anotações seguintes, por hora, vamos entender como funciona a criação dos pares que são a base do Word2Vec.&lt;/p&gt;
&lt;div class="section" id="pares"&gt;
&lt;h2&gt;Pares&lt;/h2&gt;
&lt;p&gt;vamos imaginar que já tenhamos feito todo o processo descrito no post de introdução a esta série. O que buscamos nesta etapa é apenas definir uma "janela" que será a quantidade de palavras vizinhas à uma palavra que chamaremos de central e criar pares ligando essa palavra central às vizinhas, lógico que no código real trabalharemos com ids que representam palavras e não com as palavras em si.&lt;/p&gt;
&lt;p&gt;ex.:&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;O cachorro comeu o trabalho da faculdade de novo&lt;/cite&gt;&lt;/p&gt;
&lt;p&gt;considerando a janela &lt;cite&gt;w = 2&lt;/cite&gt; teríamos:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-1"&gt;&lt;/a&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-2"&gt;&lt;/a&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"comeu"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"o"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-3"&gt;&lt;/a&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"comeu"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"cachorro"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-4"&gt;&lt;/a&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"comeu"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"o"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"comeu"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"trabalho"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-6"&gt;&lt;/a&gt;    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;a name="rest_code_9505efc5503e42e496cdc16448991b1a-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Coisas óbvias a se deduzir: a partir da palavra central, as vezes que ela aparece é sempre &lt;cite&gt;2*w&lt;/cite&gt; e em relação às vizinhas, que chamamos de palavras de contexto, a proporção sempre será de &lt;cite&gt;2*w&lt;/cite&gt; para cada palavra central, isso será importante para o cbow e para o skip-gram.&lt;/p&gt;
&lt;p&gt;Traduzindo esse procedimento bem básico em código, teremos:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# janela (window)&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;text_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_size&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;center_word_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;corpus_text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;center_word&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;context_word_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;pair_ids&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;center_word_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;context_word_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_f966f8c8a16343d194788b6b79b1ad53-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pair_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Esse será exatamente o código que teremos no método skip-gram. Mas por enquanto vamos aproveitar os métodos que usam o word2vec já implementados e vamos ver o que podemos extrair deles.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="gensim"&gt;
&lt;h2&gt;Gensim&lt;/h2&gt;
&lt;p&gt;No Gensim as operações são muito simples, basta passar para ele o texto processado de acordo com a introdução a este material:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_872b268f01ef429cb73a3bcb995bb778-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;model_sg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gensim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;compute_loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_872b268f01ef429cb73a3bcb995bb778-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;model_cb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gensim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;models&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Word2Vec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;window&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;compute_loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;No momento de criar o objeto, a única diferença nos parâmetros usados é no &lt;cite&gt;sg&lt;/cite&gt; que a essa altura já está claro que signfica skip-gram e em vez de usar True ou False, usamos 1 ou 0 para definir qual método será usado.&lt;/p&gt;
&lt;p&gt;A diferença real deles está no input e output pois ambos, cbow e skip-gram, são apenas redes neurais com pouquíssima diferença entre si como será visto posteiormente.&lt;/p&gt;
&lt;p&gt;No cbow buscamos predizer a palavra central a partir das palavras de contexto e no skip-gram fazemos o contrário, a partir da palavra central buscamos prever as palavras de contexto.&lt;/p&gt;
&lt;img alt="/images/skip-gram_cbow.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/skip-gram_cbow.png"&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_57344aa7a3dc4082ad5a46d65ae12923-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;model_sg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_examples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_57344aa7a3dc4082ad5a46d65ae12923-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;model_cb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_examples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Na prática, a função do treinamento é, a partir da proximidade entre as palavras, as camadas da rede neural vão se ajustando o que acaba indicando a proximidade de sentido entre elas, indo para um exemplo clássico queremos que seja possível, através de uma distribuição no plano cartesiano que o meio do caminho entre as palavras "rei" e "mulher" seja "rainha".&lt;/p&gt;
&lt;p&gt;## visualizando&lt;/p&gt;
&lt;p&gt;Primeiro vamos ver as dimensões na saída para cada palavra:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_b61ac146ea09431e8db88a2326cd6dd4-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;model_sg&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"turing"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;a name="rest_code_b61ac146ea09431e8db88a2326cd6dd4-2"&gt;&lt;/a&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Como podemos perceber, nos é impossível fazer uma visualização de algo em 100 dimensões, para reduzi para 2 dimensões vamos usar o sklearn com a classe PCA, como o sklearn mantém o mesmo procedimento para praticamente tudo, vou me abster de colocar o código aqui que pode ser visto no jupyter notebook com o código completo. O importante é que ao final teremos esses gráficos para cada método:&lt;/p&gt;
&lt;p&gt;obs: queria fazer algo mais interativo mas não consegui no momento&lt;/p&gt;
&lt;img alt="/images/word2vec-1.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/word2vec-1.png"&gt;
&lt;p&gt;O Gensim já tem métodos nos objetos formados para encontrar as palavras mais próximas usando a similaridade de cossenos:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# repare que quanto mais próximo de 1, mais similar&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-2"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"cianeto"&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-3"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;model_sg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_similar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="s1"&gt;'corpo'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9956434965133667&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-5"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'envenenamento'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9950364828109741&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-6"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'apesar'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9946295022964478&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-7"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'aparente'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9940468668937683&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-8"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'presença'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9939732551574707&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-9"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'descoberto'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9937050342559814&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-10"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'níveis'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9936593770980835&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-11"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'quanto'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.993450403213501&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-12"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'testada'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9933900833129883&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_0b53f65ef7ab4616af68d153a0d15180-13"&gt;&lt;/a&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'determinar'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9930295944213867&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Agora comparando o CBOW e o Skip-Gram:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"morte"&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;sg_similar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_sg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar_by_word&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;cb_similar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_cb&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;similar_by_word&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;md&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"| skip-gram | cbow |&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;|--|--|&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sg_similar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cb_similar&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;md&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"| {i[0][0]} |  {i[1][0]} |&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_13e13d41ecf944d9b5e6853da20117fe-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;Markdown&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="59%"&gt;
&lt;col width="41%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;skip-gram&lt;/th&gt;
&lt;th class="head"&gt;cbow&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;causa&lt;/td&gt;
&lt;td&gt;turing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;defende&lt;/td&gt;
&lt;td&gt;maçã&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;setembro&lt;/td&gt;
&lt;td&gt;suicídio&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;acidental&lt;/td&gt;
&lt;td&gt;após&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;estabeleceu&lt;/td&gt;
&lt;td&gt;cianeto&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;campanha&lt;/td&gt;
&lt;td&gt;computador&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;necessariamente&lt;/td&gt;
&lt;td&gt;onde&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;copeland&lt;/td&gt;
&lt;td&gt;ser&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;suicídio&lt;/td&gt;
&lt;td&gt;anos&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;resultado&lt;/td&gt;
&lt;td&gt;ter&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="notebook"&gt;
    &lt;a class="notebook-link" href="http://nbviewer.jupyter.org/github/demacdolincoln/anotacoes-nlp/blob/src/files/word2vec-1-introducao.ipynb"&gt;code&lt;/a&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>word2vec</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-1-introducao/</guid><pubDate>Thu, 06 Dec 2018 09:13:12 GMT</pubDate></item></channel></rss>