<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anotações sobre NLP</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/</link><description>Uma pequena ajuda mais prática que técnica ou teórica para quem está aprendendo sobre NLP</description><atom:link href="http://demacdolincoln.github.io/anotacoes-nlp/posts/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>pt_br</language><copyright>Contents © 2019 &lt;a href="mailto:demacdolincoln@gmail.com"&gt;Lincoln de Macêdo&lt;/a&gt; </copyright><lastBuildDate>Sun, 27 Jan 2019 04:50:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Classificação 4: RNN parte 2 (+ convolução)</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-4-rnn-parte-2-%2B-convolucao/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Nota&lt;/p&gt;
&lt;p class="last"&gt;os códigos estão aqui: &lt;a class="reference external" href="https://github.com/demacdolincoln/test-sentiment_analysis"&gt;https://github.com/demacdolincoln/test-sentiment_analysis&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Admito que eu já disse tudo o que precisava dizer nos posts anteriores, para os testes dessa última etapa, usei 2 redes neurais com apenas 1 diferença entre elas, uma usa convolução 1d e outra 2d, e por não ter muito o que falar no momento vamos direto ao que interessa.&lt;/p&gt;
&lt;div class="section" id="procedimentos"&gt;
&lt;h2&gt;Procedimentos&lt;/h2&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;init_hidden&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;recurrence (lstm)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;convolução&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="lowerroman simple"&gt;
&lt;li&gt;convolução (nn.Conv)&lt;/li&gt;
&lt;li&gt;ReLu&lt;/li&gt;
&lt;li&gt;MaxPool&lt;/li&gt;
&lt;li&gt;BatchNorm&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;funções lineares (3 no total)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="resultados"&gt;
&lt;h2&gt;Resultados:&lt;/h2&gt;
&lt;img alt="/images/classification_conv_rnn.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classification_conv_rnn.png"&gt;
&lt;p&gt;É interessante notar que mesmo não alcançando um bom resultado, o aprendizado com a convolução 1d indica um aprendizado mais "real" dentre todos até agora, talvez se seguisse o aprendizado por mais 50 ou até mesmo 100 épocas, a acurácia talvez se equiparasse à convolução 2d.&lt;/p&gt;
&lt;p&gt;Sobre a convolução 2d fica bem claro que mesmo mesmo alcançando basicamente o mesmo resultado que sem convolução, a distância entre a linha que representa os percentuais de acertos para os dados de treinamento em relação aos de teste é o maior dentre os 4 testes com redes convolucionais, isso indica um ajuste mais rápido ao treinamento ainda que para os testes tenha chegado no mesmo limite que na rnn sem convolução.&lt;/p&gt;
&lt;p&gt;Resumindo os parágrafos anteriores, a convolução 1d + rnn leva a um aprendizado mais lento, o que não é ruim, aprender muito rápido nesse contexto significa não explorar adequadamente o espaço de busca a ser percorrido pela otimização (gosto de definir algoritmos de otimização como uma busca heurística num hiperplano altamente irregular na maioria dos casos), aprender devagar tem seu lado bom mas pela ausência de garantias que chegará em aproximadamente 75% de acerto nos dados de teste, só posso concluir que tende ao underfitting, especialmente por nenhum experimento que fiz, mesmo com taxa de aprendizado mais alta conseguiu chegar a tal resultado, porém só posso ter certeza treinando por mais épocas. Por outro lado a convolução 2d + rnn tendeu ao overfitting, isso fica bem claro pela distância crescente entre a acurácia para dados de testes e treinamento. Resumindo o resumo: neste caso não necessariamente adicionar etapas como a convolução foi um bom negócio.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;table class="docutils field-list" frame="void" rules="none"&gt;
&lt;col class="field-name"&gt;
&lt;col class="field-body"&gt;
&lt;tbody valign="top"&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;post scriptum:&lt;/th&gt;&lt;td class="field-body"&gt;Pensei em fazer um post final com um resumo geral, mas agora considero isso desnecessário, no repositório ainda bagunçado com os códigos desse experimento há um notebook chamado &lt;em&gt;"relatorio.ipynb"&lt;/em&gt; onde estão os gráficos e uma tabela que indica coisas como quantidade de épocas taxas de aprendizado usadas.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>cnn</category><category>gru</category><category>lstm</category><category>rnn</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-4-rnn-parte-2-%2B-convolucao/</guid><pubDate>Sun, 27 Jan 2019 02:48:33 GMT</pubDate></item><item><title>Classificação 3: RNN parte 1</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Nota&lt;/p&gt;
&lt;p class="last"&gt;os códigos estão aqui: &lt;a class="reference external" href="https://github.com/demacdolincoln/test-sentiment_analysis"&gt;https://github.com/demacdolincoln/test-sentiment_analysis&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Nste primeiro experimento com redes neurais recorrentes, vamos apenas analisar o efeito da própria recorrência com o LSTM e GRU. Preliminarmente é preciso compreender alguns aspectos:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;O que faremos com o skip-gram treinado pelo Gensim?&lt;/li&gt;
&lt;li&gt;Em quê o LSTM ou o GRU poderão influenciar?&lt;/li&gt;
&lt;li&gt;Se a entrada tem tamanho variável, como internamente fica a rede neural?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Antes de chegar a essas explicações, essa é a classe que contém nossa rede neural:&lt;/p&gt;
&lt;table class="codetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-1"&gt; 1&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-2"&gt; 2&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-3"&gt; 3&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-4"&gt; 4&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-5"&gt; 5&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-6"&gt; 6&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-7"&gt; 7&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-8"&gt; 8&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-9"&gt; 9&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-10"&gt;10&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-11"&gt;11&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-12"&gt;12&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-13"&gt;13&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-14"&gt;14&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-15"&gt;15&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-16"&gt;16&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-17"&gt;17&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-18"&gt;18&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-19"&gt;19&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-20"&gt;20&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-21"&gt;21&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-22"&gt;22&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-23"&gt;23&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-24"&gt;24&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-25"&gt;25&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-26"&gt;26&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-27"&gt;27&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-28"&gt;28&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-29"&gt;29&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-30"&gt;30&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-31"&gt;31&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-32"&gt;32&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-33"&gt;33&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-34"&gt;34&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-35"&gt;35&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-36"&gt;36&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-37"&gt;37&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-38"&gt;38&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-39"&gt;39&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-40"&gt;40&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-41"&gt;41&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-42"&gt;42&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-43"&gt;43&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-44"&gt;44&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-45"&gt;45&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-46"&gt;46&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-47"&gt;47&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-48"&gt;48&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-49"&gt;49&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-50"&gt;50&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-51"&gt;51&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/#rest_code_edc7571fa314496bb1beb8a61c805a6f-52"&gt;52&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code python"&gt;&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;RNN&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-3"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RNN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n_layers&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-6"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-7"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-8"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-9"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-11"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-12"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_state_dict&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-13"&gt;&lt;/a&gt;            &lt;span class="s2"&gt;"weight"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FloatTensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vectors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-14"&gt;&lt;/a&gt;        &lt;span class="p"&gt;})&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-15"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-16"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="s2"&gt;"gru"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-17"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recurrence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GRU&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-18"&gt;&lt;/a&gt;        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="s2"&gt;"lstm"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-19"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recurrence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-20"&gt;&lt;/a&gt;        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-21"&gt;&lt;/a&gt;            &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="s2"&gt;"escolha entre gru e lstm apenas"&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-22"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-23"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-24"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-25"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inpt&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-29"&gt;&lt;/a&gt;        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_init_hidden&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-30"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-31"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recurrence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-32"&gt;&lt;/a&gt;            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inpt&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-33"&gt;&lt;/a&gt;            &lt;span class="n"&gt;hidden&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-34"&gt;&lt;/a&gt;        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-36"&gt;&lt;/a&gt;        &lt;span class="n"&gt;space&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-37"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-38"&gt;&lt;/a&gt;        &lt;span class="n"&gt;space&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-39"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;space&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-40"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-41"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-42"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-43"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-44"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-45"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unsqueeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-46"&gt;&lt;/a&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-47"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_init_hidden&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-48"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"lstm"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-49"&gt;&lt;/a&gt;            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-50"&gt;&lt;/a&gt;                    &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-51"&gt;&lt;/a&gt;        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-52"&gt;&lt;/a&gt;            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;div class="section" id="o-que-faremos-com-o-skip-gram-treinado-pelo-gensim"&gt;
&lt;h2&gt;1. O que faremos com o skip-gram treinado pelo Gensim?&lt;/h2&gt;
&lt;p&gt;A camada incorporada tem uma dupla função: converter a entrada (array de inteiros e de tamanho variável) em uma matriz de largura fixa, útil à célula que cuidará da recorrência, e aplicar o skip-gram, por isso ela precisa ter as seguintes dimensões [tamanho do vocabulario x dimensões do skip-gram], O que é devolvido por esta camada é uma matriz no formato [quantidade de palavras x dimensões do skip-gram].&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_74c5992f789a45a59200b572424a91af-1"&gt;&lt;/a&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_74c5992f789a45a59200b572424a91af-2"&gt;&lt;/a&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_state_dict&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
&lt;a name="rest_code_74c5992f789a45a59200b572424a91af-3"&gt;&lt;/a&gt;    &lt;span class="s2"&gt;"weight"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FloatTensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vectors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_74c5992f789a45a59200b572424a91af-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Outro fator importante que precisa ser mencionado é que esta camada também está sujeita ao treinamento da rede neural, ou seja, mantendo desse modo como está, estamos aplicando uma transferência neural, ou seja utilizando uma rede já treinada (no caso skip-gram) e continuando seu treinamento aplicado a uma outra situação, cujo treinamento neste novo contexto tende a ter um ponto de partida com maior precisão, esta é a idéia por trás da escolha de manter o treinamento ativo nesta camada, fazer com que o conteúdo aprendido no treinamento feito pelo Gensim vá se adaptando ao contexto da análise de sentimento segundo o dataset utilizado.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="em-que-o-lstm-ou-o-gru-poderao-influenciar"&gt;
&lt;h2&gt;2. Em quê o LSTM ou o GRU poderão influenciar?&lt;/h2&gt;
&lt;p&gt;Em sua estrutura, a recorrêncida da RNN se resume a uma camada oculta, uma célula de recorrência que trata do gerenciamento de memória e a entrada, olhando com atenção, a célula fará basicamente é alterar os pesos da entrada de acordo com a camada oculta, que serve como uma memória, indicando o que valorizar ou não na etapa seguinte da execução da rede neural.&lt;/p&gt;
&lt;p&gt;Traduzindo para o contexto da entrada conter a posição de cada palavra num hiperplano de acordo com o valor semântico expresso pelo uso demonstrado no dataset, isso quer dizer que será feito mais um ajuste sobre o skip-gram, na prática esse pós processamento vai indicar a importãncia de cada dimensão para cada palavra, potencializando o viés indicado pelo treinamento do skip-gram.&lt;/p&gt;
&lt;p&gt;No PyTorch temos GRU e GRUCell, e LSTM e LSTMCell, a diferença é que usando simpelsmente GRU ou LSTM estamos inserindo uma pequena rede neural com a célula indicada no nome, podemos variar a quantidade de camadas lineares e definir uma taca pra o dropout, etc, mas se usarmos GRUCell ou LSTMCell teremos apenas a célula, no experimento feito, escolhi a 1ª opção pois não custava nada para mim definir logo o dropout em vez de definir ele em algum outro ponto.&lt;/p&gt;
&lt;p&gt;Como este é um simples teste para ver o impacto da recorrência, resolvi manter apenas uma memória de curto prazo (reicinializando a cada novo uso da rede neural) para mostrar que mesmo com um uso mínimo as diferenças já são notáveis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="se-a-entrada-tem-tamanho-variavel-como-internamente-fica-a-rede-neural"&gt;
&lt;h2&gt;3. Se a entrada tem tamanho variável, como internamente fica a rede neural?&lt;/h2&gt;
&lt;p&gt;Em algum momento precisaremos de um tamanho fixo para passar pelas funções lineares, para o experimento atual apenas concatenei a matriz devolvida pelo GRU/LSTM, queria testar nas condições mais adversas, no próximo post aplicarei nesta etapa da execução tanto a convolução 1d quanto a convolução 2d, mas não há como fugir do tamanho fixo em algum momento neste caso, então a regra que usamos no post anterior de considerar o caso com maior quantidade de palavras vale aqui também.&lt;/p&gt;
&lt;table class="docutils field-list" frame="void" rules="none"&gt;
&lt;col class="field-name"&gt;
&lt;col class="field-body"&gt;
&lt;tbody valign="top"&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;obs:&lt;/th&gt;&lt;td class="field-body"&gt;um dos problemas do tamanho variável da entrada está no DataLoader do pytorch, ele lança um erro quando definimos um batch_size que nos deixe confortáveis, para trabalhar com dados em lotes ele exige tamanho fixo, de modo que só nos resta ler 1 item do dataset por vez, deixando o processo muito lento já que a cada item lido será aplicada uma etapa do treinamento, vamos ver a evolução mais rápida considerando as épocas mas a quantidade de vezes que os pesos foram atualizados correspondem a $n_epocas * n_items$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusoes"&gt;
&lt;h2&gt;Conclusões&lt;/h2&gt;
&lt;img alt="/images/classification_gru_ltsm.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classification_gru_ltsm.png"&gt;
&lt;p&gt;É notável e incrível a diferença do uso de redes recorrentes para lidar com linguagem, a grande diferença está no foco da recorrência: enquanto habitualmente ajustamos pesos para classificação, aqui transformamos os valores de entrada e diferentemente da convolução, não espalhamos informações nem produzimos matrizes ou arrays equivalente mas ajustamos a entrada de modo a se adequar melhor ao contexto do treinamenhto, e o melhor de tudo: sabendo lidar com sequências em nível mais abstrato do que apenas arrays e matrizes, o contexto envolta da ordem que as palavras são usadas nas frases tem relevância para a recorrência, e mesmo aplicando tão minimamente e de forma tão pouco eficiente neste exemplo, o resultado já superou largamente o uso de redes convolucionais demonstradas na anotação anterior.&lt;/p&gt;
&lt;p&gt;No próximo post vou misturar as coisas, aplicando a recorreência, depois convlução (1d e 2d), e por último camadas lineares, assim espero concluir os modelos temporariamente e fazer uma análise geral sobre o que os métodos apresentados ao longo dessas anotações sobre classificação influenciam os resultados.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>gru</category><category>lstm</category><category>rnn</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/</guid><pubDate>Sun, 20 Jan 2019 21:08:26 GMT</pubDate></item><item><title>Resumos 0: PageRank</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/resumos-0-pagerank/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Esta é uma anotação introdutória ao problema de resumir textos, o ponto principal abordado aqui será a dificuldade de identificar o que é relevante, para isso usei o textrank, não entrarei em muitos detalhes sobre esse algoritmo, tratando de forma intuitiva a idéia geral que será mais aprofundada em anotações posteriores.&lt;/p&gt;
&lt;p&gt;PageRank foi o primeiro algoritmo usado pelo google para rankear os links de sua busca, logicamente o google evoluiu neste tempo todo e usa uma combinação de vários algoritmos e não o pagerank puro, aqui o usaremos para rankear os parágrafos de um texto da wikipedia.&lt;/p&gt;
&lt;div class="section" id="funcionamento"&gt;
&lt;h2&gt;Funcionamento&lt;/h2&gt;
&lt;p&gt;Não entrarei em muitos detalhes sobre o algoritmo, então explicando de forma superficial temos o fato do pagerank se valer de um grafo, e ao considerar o grau de cada nó, ou seja a quantidade de conexões de cada nó, e um peso atribuído a cada conexão, teremos um ranking de importância. Até mesmo explicando desse modo já imaginamos como o algoritmo se aplica bem a links entre páginas na internet, mas para textos ele realmente não é tão adequado porém é didático como algo introdutório.&lt;/p&gt;
&lt;p&gt;Os passos do "resumo" que na verdade é um rankeamento:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;extrair estatísticas do texto (&lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa"&gt;tf-idf&lt;/a&gt; ou &lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/word2vec-1-introducao"&gt;word2vec&lt;/a&gt;, enfim, qualquer coisa que nos diga algo sobre o texto)&lt;/li&gt;
&lt;li&gt;gerar uma matriz de similaridade, que na verdade servirá como matriz adjacente&lt;/li&gt;
&lt;li&gt;converter a matriz adjacente num grafo&lt;/li&gt;
&lt;li&gt;aplicar o PageRank&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="implementacao"&gt;
&lt;h2&gt;Implementação&lt;/h2&gt;
&lt;p&gt;Resolvi o skip-gram já treinado[1]_ e a página da wikipédia sobre Alan Turing como já feito antes, o processamento realmente começa criando listas com os valores correspondentes a cada palavra indicado pelo skip-gram.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_7f655bc01807478aaf8481b70fbbbc42-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;sentences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_7f655bc01807478aaf8481b70fbbbc42-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_7f655bc01807478aaf8481b70fbbbc42-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;paragraph&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7f655bc01807478aaf8481b70fbbbc42-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word2id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;paragraph&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;id2word&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;O passo seguinte é criar uma matriz quadrada onde cada lado tem o nº de parágrafos, preenchi a matriz da seguinte forma:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentences&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-3"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-4"&gt;&lt;/a&gt;            &lt;span class="n"&gt;similarity_matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-5"&gt;&lt;/a&gt;                                          &lt;span class="n"&gt;cosine_similarity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_d8741e6eb8c448659e1aecdaddf604bc-6"&gt;&lt;/a&gt;                                      &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;O que é feito acima é apenas comparar a similaridade de cossenos entre cada parágrafo, indicando de alguma forma algum nível de similaridade, de modo que o parágrafo com maior &lt;strong&gt;índice de similaridade&lt;/strong&gt; em relação aos demais será aquele que melhor representa o conjunto.&lt;/p&gt;
&lt;img alt="/images/similarity_matrix-classificacao-1.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/similarity_matrix-classificacao-1.png"&gt;
&lt;p&gt;Essa é uma matriz simétrica que seŕá lida como uma matriz adjacente de um grafo, cada linha e coluna serão nós e cada corrdenada indica o peso do vértice que liga cada nó, um dos problemas dessa estratégia é que todos os nós terão o mesmo grau, já que todos se ligam a todos, isso acaba inutilizando o uso do grau de cada nó para o pagerank, tendo como único parâmetro a considerar o peso dos vértices.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;G&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_numpy_array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;similarity_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pagerank&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;G&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;original&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-5"&gt;&lt;/a&gt;    &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"original_text-Alan_Turing.pickle"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"rb"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-6"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;word_rank&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-9"&gt;&lt;/a&gt;            &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;original&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-10"&gt;&lt;/a&gt;            &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-11"&gt;&lt;/a&gt;            &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-12"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-14"&gt;&lt;/a&gt;    &lt;span class="n"&gt;qnt_lines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-15"&gt;&lt;/a&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-16"&gt;&lt;/a&gt;    &lt;span class="n"&gt;top&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word_rank&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;qnt_lines&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-18"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;qnt_lines&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-19"&gt;&lt;/a&gt;        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"-- parágrafo do resumo: {i} | parágrafo original: {top[i][1]}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_987e3760b0b646bb83d961a7d99e45cd-20"&gt;&lt;/a&gt;        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Na saída do código acima podemos reparar que a ordem de importância dada a cada parágrafo não necessariamente está relacionado ao seu tamanho ou à sua posição no texto:
.. epigraph:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
-- parágrafo do resumo: 0 | parágrafo original: 19
Por muitos anos, foram feitas campanhas que envolveram ativistas da tecnologia da informação, do meio político e do público LGBT. Em 11 de setembro de 2009, 55 anos após sua morte, o primeiro-ministro do Reino Unido, Gordon Brown, seguindo um pedido feito através de uma petição direcionada ao governo britânico, pediu desculpas formais em nome do governo pelo tratamento preconceituoso e desumano dado a Turing, que o levou ao suicídio. Em 24 de dezembro de 2013, passou a ter efeito a Real Prerrogativa do Perdão, concedida a Turing pela Rainha Elizabeth II, a pedido do ministro da justiça do Reino Unido, Chirs Grayling, depois que uma petição criada em 2012 obteve mais de 37.000 assinaturas solicitando o devido perdão.

-- parágrafo do resumo: 1 | parágrafo original: 3
A homossexualidade de Turing resultou em um processo criminal em 1952, pois atos homossexuais eram ilegais no Reino Unido na época, e ele aceitou o tratamento com hormônios femininos e castração química, como alternativa à prisão. Morreu em 1954, algumas semanas antes de seu aniversário de 42 anos, devido a um aparente autoadministrado envenenamento por cianeto, apesar de sua mãe (e alguns outros) terem considerado sua morte acidental. Em 10 de setembro de 2009, após uma campanha de internet, o primeiro-ministro britânico Gordon Brown fez um pedido oficial de desculpas público, em nome do governo britânico, devido à maneira pela qual Turing foi tratado após a guerra. Em 24 de dezembro de 2013, Alan Turing recebeu o perdão real da rainha Elizabeth II, da condenação por homossexualidade.

-- parágrafo do resumo: 2 | parágrafo original: 12
Em 1938, Turing se uniu ao GC&amp;amp;CS, o braço de decodificação de mensagens da inteligência britânica, para efetuar a Criptoanálise da Máquina Enigma. O Enigma era uma máquina de codificação que mudava seus códigos diariamente, obrigando a que o projeto de decifração se tornasse bastante rápido. Após o Reino Unido iniciar a Segunda Guerra Mundial ao declarar guerra à Alemanha em 1939, Turing foi direcionado para o quartel da GC&amp;amp;CS em Bletchley Park. A partir de uma máquina decodificadora polonesa, Turing projetou a Bomba eletromecânica ("Bombe"),  um equipamento eletromecânico que ajudaria a decriptar as mensagens do Enigma e foi montada em 1940. Novas Bombas foram construídas após Turing e sua equipe pedirem apoio a Winston Churchill, e mais de duzentas operavam ao fim da Guerra em 1945. Turing também introduziu sua equipe em Bletchley Park ao matemático Tommy Flowers, que em 1943 projetou o Colossus, um computador primitivo que ajudou a decodificar outra máquina criptográfica alemã, o Lorenz.
&lt;/pre&gt;
&lt;p&gt;Logicamente eu poderia ter usado frases em vez de parágrafos para fazer o resumo, talvez até fizesse mais sentido chamar a saída do código de resumo, mas resolvi usar parágrafos inteiros por considerar que a idéia fica mais clara assim e ao comparar com o texto original, fica mais visualmente evidente como se deu o trabalho do pagerank, nos próximos posts sobre este tópico serão mostradas redes neurais que fazem um trabalho bem mais coerente, logicamente usarei redes neurais recorrentes e o seq2seq, portanto recomendo que veja as anotações que escrevi sobre esses temas:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm"&gt;GRU e LSTM&lt;/a&gt;
&lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/seq2seq-introducao"&gt;seq2seq: introdução&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;_[1] &lt;a class="reference external" href="http://www.nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc"&gt;http://www.nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>modelagem</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/resumos-0-pagerank/</guid><pubDate>Tue, 25 Dec 2018 16:31:18 GMT</pubDate></item><item><title>Classificação 2: CNN</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-2-cnn/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Nota&lt;/p&gt;
&lt;p class="last"&gt;os códigos estão aqui: &lt;a class="reference external" href="https://github.com/demacdolincoln/test-sentiment_analysis"&gt;https://github.com/demacdolincoln/test-sentiment_analysis&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Como falado &lt;cite&gt;anteriormente &amp;lt;link://filename/posts/classificacao-1.rst&amp;gt;_&lt;/cite&gt;, classificar um texto é algo que vai além do vocabulário ainda que a gente utilize o word2vec ou o glove, e como a ordem das palavras importa muito, vamos dar aqui o 1º passo neste sentido, vamos ver como funciona uma rede neural convolucional (CNN) aplicada à classificação de textos.&lt;/p&gt;
&lt;p&gt;Habitualmente elas são usadas essencialmente em processamento de imagens, no caso o que teremos é uma linha representando cada palavra e as colunas representando um ponto no hiperplano de acordo com a veotrização treinada. A idéia por trás da convolução aqui aplicada é bastante simples: ter uma matriz maior e calcular uma matriz menor equivalente, neste processo há perda de dados e portanto é irreversível, porém tem se demonstrado muito útil em muitos casos.&lt;/p&gt;
&lt;div class="section" id="implementacao"&gt;
&lt;h2&gt;Implementação:&lt;/h2&gt;
&lt;p&gt;O primeiro passo é transformar um texto numa matriz, para isso vamos recordar o que temos:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;texto ~&amp;gt; sequência de ids de palavras&lt;/li&gt;
&lt;li&gt;skip-gram, cbow, glove, etc. ~&amp;gt; representação cartesiana de palavras segundo o sentido compreendido pelo seu uso&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Diante disso se torna meio lógico fazer uma matriz no formato &lt;cite&gt;words x embedding dims&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;Um dos problemas dessa abordagem é que frases tem tamanhos variáveis enquanto a matriz de entrada na camada convolucional da CNN precisa ter tamanho fixo, então temos de lidar sempre com o pior caso, frases grandes, e preencher o espaço restante das frases menores com zeros, isso acaba nos obrigando a ter um custo computacional extra já que teremos muitos espaços em branco só para que sempre tenhamos matrizes do mesmo tamanho.&lt;/p&gt;
&lt;p&gt;Antes de continuar preciso fazer algumas observações:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Não encontrei um dataset em PTBR bom o suficiente, portanto, contrariando minha proposta inicial, o ciclo de anotações sobre classificação usará um dataset em inglês.&lt;/li&gt;
&lt;li&gt;Tentei baixar um word embedding já treinado com o vocabulário da língua inglesa, mas ele tinha mais de 6Gb, como esse fato ia complicar algumas coisas a nível operacional, diminuindo minha proposta de fazer as anotações da forma mais simples possível, preferi usar o Gensim para calcular o skip-gram estrito ao dataset.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="primeiros-passos"&gt;
&lt;h2&gt;Primeiros passos:&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Baixar o dataset: link&lt;/li&gt;
&lt;li&gt;E o de sempre conforme mostrado em &lt;a class="reference external" href="filename://posts/word2vec-1-introducao.rst"&gt;Word2vec 1: introdução&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sobre o tamanho das dimensões no word2vec: como neste caso precisamos de uma matriz quadrada, precisamos que a quantidade de dimensões seja a mesma do maior texto depois do processo de limpeza.&lt;/p&gt;
&lt;p&gt;Após isso ser feito podemos montar as matrizes:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;phrase&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model_vec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;phrase&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;phrase&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gensim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;simple_preprocess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;phrase&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;phrase&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;phrase&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;phrase&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-8"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model_vec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-9"&gt;&lt;/a&gt;            &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model_vec&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-13"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-14"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-15"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-16"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FloatTensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-17"&gt;&lt;/a&gt;            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;make_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-18"&gt;&lt;/a&gt;        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-19"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LongTensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-20"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-21"&gt;&lt;/a&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-22"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__getitem__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-23"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-24"&gt;&lt;/a&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-25"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__len__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_0aeeabbc377c4dfc8a9082294fed8bdd-26"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_len&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Para facilitar a divisão do dataset para uma valização cruzada, usei o sklearn bem pontualmente:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_8ad115fc588b40eaabb4b44b0888b3bd-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;train_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8ad115fc588b40eaabb4b44b0888b3bd-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_8ad115fc588b40eaabb4b44b0888b3bd-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;data_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip_gram&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stopw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8ad115fc588b40eaabb4b44b0888b3bd-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;data_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip_gram&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stopw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="modelo-de-rede-neural"&gt;
&lt;h2&gt;Modelo de rede neural:&lt;/h2&gt;
&lt;p&gt;A rede neural será uma rede convolucional bem padrão:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CNN_2D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin_out&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-3"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CNN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-6"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-7"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-8"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPool2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-9"&gt;&lt;/a&gt;        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-11"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-12"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-13"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-14"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPool2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-15"&gt;&lt;/a&gt;        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-17"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-20"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-21"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-22"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-23"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_a51030f6300d48fabc0d86b37ffc48ba-24"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Para entender melhor como a convolução funciona neste contexto, recomendo os vídeos:
* video1
* video2&lt;/p&gt;
&lt;p&gt;Uma vantagem da convolução 2d (com uma matriz e não com um array) é uma maior propagação de informação sobre áreas tomadas pelos zeros, se formos imaginar o processo num array logo percebemos um espaço muito limitado de propagação das informações finais apenas. Para expor melhor as diferenças óbvias em se trabalhar com 1 e com 2 dimensões, também repeti o experimento com uma rede convolucional 1d, ela apresenta pouquíssimas diferenças: menores dimensões no skip-gram (apenas 10), 3 camadas lineares na rede neural, maior quantidade de épocas no treinamento. Em todos os casos resolvi usar uma função sigmoide na saída, isso para ter uma estimativa de "certeza" quanto às escolhas da rede neural após o treinamento, mas deixarei essa análise comparativa para o último post desse ciclo.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CNN_1D&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lin_out&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-3"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CNN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-5"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-6"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Conv1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stride&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-7"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReLU&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-8"&gt;&lt;/a&gt;            &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MaxPool2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-9"&gt;&lt;/a&gt;        &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-11"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-13"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-14"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-15"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lin_in&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;lin_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-19"&gt;&lt;/a&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-20"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-21"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-22"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-23"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-24"&gt;&lt;/a&gt;        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_e08329b2b91c461e950a0bb63f69eac5-25"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Como acho a idéia aqui não ficou tão clara, antes de continuar, vou apenas ressaltar dimensões de entrada para cada rede neural:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Conv2d:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;altura: tamanho máximo de palavras&lt;/li&gt;
&lt;li&gt;largura: tamanho máximo de palavras&lt;/li&gt;
&lt;li&gt;word embedding dims: tamanho máximo de palavras&lt;/li&gt;
&lt;li&gt;a matriz será: palavras x word embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Conv1d:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;tamanho: tamanho máximo de palavras * word embedding dims&lt;/li&gt;
&lt;li&gt;word embedding dims: qualquer tamanho que queira, no caso eu escolhi 10&lt;/li&gt;
&lt;li&gt;o array será: dimensões de cada palavra lida na ordem colocada uma após a outra num array&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="treinamento"&gt;
&lt;h2&gt;Treinamento:&lt;/h2&gt;
&lt;p&gt;Como pretendo fazer um post final de análise dos resultados, usei o ignite para organizar a criação de um csv e salvar a rede neural ao final do treinamento, não entrarei em muitos detalhes mas basta ver o notebook usado que (ao menos espero) fique bem clara a utilidade.&lt;/p&gt;
&lt;p&gt;Em todos os experimentos, para as comparações serem mais justas, usarei essencialmente os mesmos parâmetros:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;loss function: Cross Entropy&lt;/li&gt;
&lt;li&gt;Optimizer: Adam&lt;/li&gt;
&lt;li&gt;learning rate: 0.001&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apesar de ser um dataset muito pequeno, com apenas 3000 textos no total e invariavelmente fadado ao overfitting justamente por causa disso, a rede convolucional 2d funcionou muito melhor que a 1d como os gráficos abaixo claramente demonstram:&lt;/p&gt;
&lt;img alt="/images/classification_conv.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classification_conv.png"&gt;
&lt;p&gt;&lt;strong&gt;resultado final:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Na próxima anotação será a vez de tratar de redes recorrentes, serão no total 3 redes neurais (1 na próxima anotação e 2 na seguinte), inicialmente lidando apenas com a recorrência comparando o desempenho do GRU e LSTM e posteriormente combinado a recorrência com a convolução, mas para adiantar as coisas recomendo começar a ler a respeito do &lt;a class="reference external" href="filename://posts/gru-e-lstm.rst"&gt;LSTM e GRU&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leituras-recomendadas"&gt;
&lt;h2&gt;Leituras recomendadas:&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/abs/1408.5882"&gt;https://arxiv.org/abs/1408.5882&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>cnn</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-2-cnn/</guid><pubDate>Tue, 25 Dec 2018 08:17:55 GMT</pubDate></item><item><title>GRU e LSTM</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;obs: Não vou me demorar tratando de questões teóricas sobre as RNN em si, já que o foco dessas anotações é NLP, futuramente, ao concluir essas anotações talvez eu inicie uma série mais abrangente sobre machine learning, mas por enquanto apenas traterei de assuntos teóricos relativos a NLP e ao resto apenas uma abordagem prática.&lt;/p&gt;
&lt;p&gt;Parece meio óbvio dizer mas o que define uma rede neural recorrente é exatamente a recorrência, isto é, informações que são armazenadas e depois reutilizadas, a forma mais simples de implementação consiste em criar uma camada (um array) que armazena os resultados e é utilizado normalmente no processamento dos dados que passam por uma rede neural, só que com 1 caracérística distinta: haver uma condição ou não para atualizar esses dados aprendidos ao longo do treinamento e uma condição que a informação armazenada seja utilizada.&lt;/p&gt;
&lt;p&gt;Devido a esse mecanismo ser claramente um gerenciamento de memória e estarmos tratando de redes neurais, não demora muito para começarmos a associar ao modo como nosso cérebro gerencia a memória, desta forma vem ao mundo em 1997 o LSTM (Long Short-Term Memory) &lt;a class="footnote-reference" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id4" id="id1"&gt;[1]&lt;/a&gt; &lt;a class="footnote-reference" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id5" id="id2"&gt;[2]&lt;/a&gt;, e como o nome bem indica, se trata de gerenciamento de memória de curto e longo prazo, posteriormente, em 2014 nasce o GRU (Gated Recurrent Unit) &lt;a class="footnote-reference" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id6" id="id3"&gt;[3]&lt;/a&gt;, mantendo diversas semelhanças com o LSTM porém com um custo computacional um pouco menor mas que no geral tem um desempenho semelhante ainda que é comum encontrar artigos falando que um ou outro método funcionou bem melhor em algum caso específico. Mas aqui estamos tratando de entender por alto como funciona esse gerenciamento de memória, o que precisamos ter noção é de como eles fazem isso?&lt;/p&gt;
&lt;div class="section" id="portoes"&gt;
&lt;h2&gt;Portões&lt;/h2&gt;
&lt;p&gt;Portões == funções&lt;/p&gt;
&lt;img alt="https://upload.wikimedia.org/wikipedia/commons/3/3b/The_LSTM_cell.png" src="https://upload.wikimedia.org/wikipedia/commons/3/3b/The_LSTM_cell.png"&gt;
&lt;object data="https://upload.wikimedia.org/wikipedia/commons/3/37/Gated_Recurrent_Unit%2C_base_type.svg" type="image/svg+xml"&gt;
https://upload.wikimedia.org/wikipedia/commons/3/37/Gated_Recurrent_Unit%2C_base_type.svg&lt;/object&gt;
&lt;p&gt;Explicando as imagens acima: a primeira mostra como funciona o LSTM e a segunda mostra como funciona o GRU, ainda que os diagramas sejam diferentes, vemos que as funções usadas, os "portões" são os mesmos embora aplicados de diferentes formas, como são as funções que importam para entender aidéia geral, vou direto à explicação sobre as funções.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sigma = \frac{1}{1 + exp(-x)}
\end{equation*}
&lt;/div&gt;
&lt;div class="math"&gt;
\begin{equation*}
tanh = \frac{e^x - e^-x}{e^x + e^{-x}}
\end{equation*}
&lt;/div&gt;
&lt;img alt="/images/lstm_gru-tanh-sigmoid.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/lstm_gru-tanh-sigmoid.png"&gt;
&lt;p&gt;Vemos que a diferença entre os gráficos dessas funções é essencialmente o limite quando tende a menos infinito, e isso faz toda a diferença, pois um limite que tende a 0 significa que posteriormente qualquer número multiplicado por 0 será 0, neste caso a função sigmoide indica a relevância de cada dimensão de entrada, se a dimensão for próxima a zero, ela vai perdendo relevância até desaparecer ou ser substituída por outra informação mais relevante (decidida pela função tanh).&lt;/p&gt;
&lt;p&gt;Todo o mecanismo de preservação e esquecimento desses métodos se baseia nesses "portões" que é como são chamadas as camadas com a função sigmoide, enquanto a função tanh tem o dever de fazer as escolhas finais, repare nas somas e multiplicações que unem o fluxo da saída com a camada oculta que armazena a memória, como a última estapa das operações com o estado da célula é sempre uma soma e os anteriores são multiplicações, isso revela a alteração dos pesos para definir a importância de cada dimensão e posteriormente a atualização mantendo assim para a época atual do treinamento da rede neural, a memória de curto prazo (os espaços próximos a zero que após a soma se mantém próximos aos resultados mais recentes) e a memória de longo prazo (o conteúdo mais relevante deixado mais próximo de 1)&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="artigos-e-links-recomendados"&gt;
&lt;h2&gt;artigos e links recomendados&lt;/h2&gt;
&lt;p&gt;Uma das melhores explicações que já encontrei sobre LSTM e GRU: &lt;a class="reference external" href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"&gt;Illustrated Guide to LSTM’s and GRU’s: A step by step explanation&lt;/a&gt;&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709"&gt;Learning to Forget: Continual Prediction with LSTM ( Felix A. Gers , Jürgen Schmidhuber , Fred Cummins )&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id5" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.researchgate.net/profile/Sepp_Hochreiter/publication/13853244_Long_Short-term_Memory/links/5700e75608aea6b7746a0624/Long-Short-term-Memory.pdf?origin=publication_detail"&gt;Long short-term memory (Sepp Hochreiter; Jürgen Schmidhuber)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/#id3"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1406.1078v3.pdf"&gt;Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation ( Cho, Kyunghyun; van Merrienboer, Bart; Gulcehre, Caglar; Bahdanau, Dzmitry; Bougares, Fethi; Schwenk, Holger; Bengio, Yoshua)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm/</guid><pubDate>Mon, 24 Dec 2018 05:13:54 GMT</pubDate></item><item><title>Seq2Seq - Implementação</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/seq2seq-implementacao/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;span&gt;&lt;/span&gt;</description><category>modelagem</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/seq2seq-implementacao/</guid><pubDate>Mon, 24 Dec 2018 05:13:25 GMT</pubDate></item><item><title>Seq2Seq - Introdução</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/seq2seq-introducao/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Tenho certeza que todos ao menos uma vez se perguntaram, pelo menos nas primeiras vezes que usaram o google translate, "como é que isso funciona? é magica?", até mesmo pelo que escrevi aqui até agora, todos os conteúdos estão bastante distantes de algo que trate tão intensamente com linguagem do que o desta anotação. O seq2seq nos permite criar redes que aprendam a sequência em que as palavras estão dispostas num texto de modo que fique fácil gerar textos, por hora, para simplificar esse assunto bastante extendo, traterei aqui apenas de explicar cada passo praticamente sem o código e na próxima anotação terá uma implementação completa.&lt;/p&gt;
&lt;div class="section" id="encoder-decoder"&gt;
&lt;h2&gt;encoder - decoder&lt;/h2&gt;
&lt;p&gt;O grande "truque" está no mecanismo de codificação-decodificação, na prática são 2 redes neurais recorrentes bem simples que compartilham uma mesma camada oculta e não tem camada de ativação, só uma célula &lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/gru-e-lstm"&gt;GRU ou LSTM&lt;/a&gt; que realiza o processamento.&lt;/p&gt;
&lt;p&gt;A informação que dá sentido à ambas as redes é a camada oculta, é sobre ela que incide o treinamento, portanto essa é a camada responsável por fazer a relação entre as saídas de cada rede neural.&lt;/p&gt;
&lt;p&gt;Então o que temos até o momento é:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;encoder:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;hidden layer&lt;/li&gt;
&lt;li&gt;gru&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;decoder:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;hidden layer&lt;/li&gt;
&lt;li&gt;gru&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="treinamento"&gt;
&lt;h2&gt;Treinamento&lt;/h2&gt;
&lt;p&gt;Como já disse que tudo está em torno da camada oculta compartilhada, é criando este array que se inicia o treinamento, que incide mais sobre a camada de decodificação que sobre a de encodificação, é feito desse modo pela camada de decodificação ser a usada para calcular a perda já que é ela que nos fornecerá a saída final do algoritmo.&lt;/p&gt;
&lt;p&gt;Procedimento:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;hidden layer&lt;/li&gt;
&lt;li&gt;encoder_output, hidden_layer = encoder(input, hidden_layer)&lt;/li&gt;
&lt;li&gt;decoder_output, hidden_layer = decoder(encoder_output, hidden_layer)&lt;/li&gt;
&lt;li&gt;loss(decoder_output, target)&lt;/li&gt;
&lt;li&gt;backward&lt;/li&gt;
&lt;li&gt;step&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Na próxima anotação sobre o seq2seq, diante do código, tudo ficará mais claro.&lt;/p&gt;
&lt;p&gt;Resolvi não colocar imagens ilustrativas aqui pois no 1º link das leituras recomendadas há um monte de animações explicando bem detalhadamente todo o processo, das 2 leituras recomendadas, essa é a que mais recomendo.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leituras-recomendadas"&gt;
&lt;h2&gt;leituras recomendadas&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"&gt;http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://google.github.io/seq2seq/"&gt;https://google.github.io/seq2seq/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>modelagem</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/seq2seq-introducao/</guid><pubDate>Mon, 24 Dec 2018 05:13:03 GMT</pubDate></item><item><title>Classificação 1</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;O problema fundamental da classificação de textos reside no fato da dificuldade de representar o texto a nível numérico, ainda que o word2vec, o glove, o seq2seq sejam realmente úteis assim como vários outros algoritmos que não incluí aqui mas que são facilmente encontrados em buscas no google, eles por si só não conseguem ir além da representação semântica ou de alguma outra lógica sobre as palavras, tanto para gerar textos quanto para classificá-los precisamos do auxílio de outros algoritmos. O objetivo desta anotação é identificar os desafions inerentes a esta tarefa.&lt;/p&gt;
&lt;div class="section" id="apenas-vocabulario"&gt;
&lt;h2&gt;Apenas vocabulário&lt;/h2&gt;
&lt;p&gt;Esse seria o caminho mais óbvio, tendo em vista que temos uma representação espacial da disposição das palavras num hiperplano, então faz sentido imaginar que textos sobre diferentes assuntos necessariamente tem diferentes vocabulários. Façamos um teste:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;peguei 2 textos da wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol class="loweralpha simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.wikipedia.org/wiki/Lutefisk"&gt;Lutefisk&lt;/a&gt; - um prato da culinária norueguesa&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://pt.wikipedia.org/wiki/Erhu"&gt;Erhu&lt;/a&gt; - um instrumento tradicional chinês&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;fiz o pré-processamento das palavras como já descrito em outro post, ficando apenas com o vocabulário&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;peguei as posições correspondentes a cada palavra no skip-gram já treinado&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;reduzi as dimensões e plotei o gráfico&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="/images/classificacao_1_scatter_vec.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classificacao_1_scatter_vec.png"&gt;
&lt;p&gt;&lt;strong&gt;explicando as cores:&lt;/strong&gt;&lt;/p&gt;
&lt;!-- vermelho: vocabulário do texto 1 --&gt;
&lt;!-- ciano: vocabulário do texto 2 --&gt;
&lt;!-- branco: vocabulário em comum a ambos --&gt;
&lt;p&gt;Como é possível perceber acima, não identificamos um nível de separação consistente entre os vocabulários, olhando a densidade de concentração do vocabulário nos dois textos, descartando as palavras em comum, temos a imagem abaixo:&lt;/p&gt;
&lt;img alt="/images/classificacao_1_kde_vec.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/classificacao_1_kde_vec.png"&gt;
&lt;p&gt;Os centros estão muito próximos, ou seja, mesmo identificando as regiões mais densas nos vocabulários, ao tentar usar esta região como métrica, a similaridade de sentido entre os termos para o texto 1 e para o texto 2 continuam muito próximas tornando essa estratégia bem ineficaz.&lt;/p&gt;
&lt;p&gt;A solução está na compreensão que um texto não são apenas palavras soltas, mas o sentifo extrapola a simples junção de palavras, então a ordem do que está escrito importa, a disposição das palavras no texto importa muito.&lt;/p&gt;
&lt;p&gt;Nas próximas anotações abordarei sobre o uso de redes convolucionais e redes neurais recorrentes, diferentes formas de tentar burlar as dificuldades aqui apresentadas.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-1/</guid><pubDate>Mon, 24 Dec 2018 05:12:26 GMT</pubDate></item><item><title>Distância Euclidiama vs Similaridade de Cossenos</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Indo direto ao ponto a principal diferença entre os cálculos é que enquanto na distância euclidiana é como se fizéssemos uma medição com uma régua entre 2 pontos, na similaridade de cossenos analisamos a distância angular entre 2 pontos a partir da origem, isso ficará mais claro no gráfico perto do final desta anotação.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
dist\_eucl = \sqrt{\sum{(a-b)^2}}
\end{equation*}
&lt;/div&gt;
&lt;div class="math"&gt;
\begin{equation*}
cosine\_sim = \frac{\sqrt{\sum{a * b}}}{\sqrt{\sum{a^2}} * \sqrt{\sum{b^2}}}
\end{equation*}
&lt;/div&gt;
&lt;div class="section" id="comparando-resultados"&gt;
&lt;h2&gt;Comparando resultados&lt;/h2&gt;
&lt;p&gt;Primeiro vamos implementar cada cálculo e depois uma função que receba uma matriz, normalize os dados, e indike os "k" pontos mais próximos a alguma coordenada que a gente escolher. Como usaremos em outras anotações, escrevi mais linhas do que um código simples e didático deveria ter:&lt;/p&gt;
&lt;table class="codetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-1"&gt; 1&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-2"&gt; 2&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-3"&gt; 3&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-4"&gt; 4&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-5"&gt; 5&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-6"&gt; 6&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-7"&gt; 7&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-8"&gt; 8&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-9"&gt; 9&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-10"&gt;10&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-11"&gt;11&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-12"&gt;12&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-13"&gt;13&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-14"&gt;14&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-15"&gt;15&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-16"&gt;16&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-17"&gt;17&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-18"&gt;18&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-19"&gt;19&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-20"&gt;20&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-21"&gt;21&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-22"&gt;22&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-23"&gt;23&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-24"&gt;24&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-25"&gt;25&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-26"&gt;26&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-27"&gt;27&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/#rest_code_7361953c4e44408fbac34e1192d4a6f5-28"&gt;28&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code python"&gt;&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;euclidean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cosine&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;knn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"cos"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kw&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;data_norm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coord_norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"coord"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-11"&gt;&lt;/a&gt;        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;kw&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"coord"&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;ata_norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;coord_norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data_norm&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-14"&gt;&lt;/a&gt;    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-15"&gt;&lt;/a&gt;        &lt;span class="n"&gt;data_norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-16"&gt;&lt;/a&gt;        &lt;span class="n"&gt;coord_norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data_norm&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;kw&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"pos"&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-18"&gt;&lt;/a&gt;    &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data_norm&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-20"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;"cos"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-21"&gt;&lt;/a&gt;            &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cosine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coord_norm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-22"&gt;&lt;/a&gt;        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-23"&gt;&lt;/a&gt;            &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;euclidean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coord_norm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-24"&gt;&lt;/a&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-25"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;"cos"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-26"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_7361953c4e44408fbac34e1192d4a6f5-28"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Visualizando a diferença de resultados entre as medições, gerei esse gráfico abaixo:&lt;/p&gt;
&lt;a class="reference external image-reference" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/eucl_vs_cos.png"&gt;&lt;img alt="/images/eucl_vs_cos.thumbnail.png" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/eucl_vs_cos.thumbnail.png" style="width: 500px;"&gt;&lt;/a&gt;
&lt;p&gt;explicando: os pontos vermelhos representam os pontos mais próximos desse ponto amarelo cortado por uma seta são os pontos mais próximos considerando a distância euclidiana, os pontos azuis é pela similaridade de cossenos e os roxos são os que as duas métricas coincidem ao listar os mais próximos, a seta indica a inclinação do ponto amarelo em relação a origem, e é isso que a similaridade de cossenos leva em consideração, perceba que um dos pontos azuis ficou bem distante mas projetando a seta vemos que se mantém mais próximo ao ângulo do ponto amarelo que o ponto vemelho.&lt;/p&gt;
&lt;p&gt;O motivo de preferirmos usar a similaridade de cossenos a usar distância euclidiana ou outras métricas para medir distâncias é que quando trabalhamos com NLP e ainda mais quando fazemos uma redução de dimensionalidade (onde ficou claro que há rotação e distorção) os ângulos ficam mais bem preservados que as distâncias.&lt;/p&gt;
&lt;p&gt;obs: É muito comum a similaridade é calculada com 1 passo a mais do que o demonstrado aqui, a distância angular é dada por:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
dist\_angular = \frac{cos^-1(cos\_similarity)}{\pi}
\end{equation*}
&lt;/div&gt;
&lt;div class="math"&gt;
\begin{equation*}
angular\_similarity = 1-dist\_angular
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Outras vezes apenas fazem &lt;strong&gt;1-similaridade&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="notebook"&gt;
    &lt;a class="notebook-link" href="http://nbviewer.jupyter.org/github/demacdolincoln/anotacoes-nlp/blob/src/files/knn_eucl_cos.ipynb"&gt;code&lt;/a&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>utils</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/distancia-euclidiama-vs-similaridade-de-cossenos/</guid><pubDate>Fri, 07 Dec 2018 07:04:17 GMT</pubDate></item><item><title>Estatística: TF-IDF e LSA</title><link>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/</link><dc:creator>Lincoln de Macêdo</dc:creator><description>&lt;div&gt;&lt;p&gt;Antes da popularidade de métodos baseados em IA, muito também devido à capacidade dos computadores da época, o que restava para análises de texto era quantificar as palavras e buscar extrair estatísticas, o mais básico e fundamental talvez seja o TF-IDF e por isso este post.&lt;/p&gt;
&lt;table class="docutils field-list" frame="void" rules="none"&gt;
&lt;col class="field-name"&gt;
&lt;col class="field-body"&gt;
&lt;tbody valign="top"&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;tf-idf:&lt;/th&gt;&lt;td class="field-body"&gt;&lt;em&gt;frequency-inverse document frequency&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Este método se resume a contar a frequência de uso de palavras e realizar um cálculo que gere uma estimativa de uso/importância da palavra no texto, de certa forma ele se conecta à &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law"&gt;Lei de Zipf&lt;/a&gt; que trata justamente de uma análise da frequência de palavras.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
TF(t) = \frac{nº\ de\ vezes\ que\ t\ aparece\ no\ texto}{total\ de\ termos\ no\ texto}
\end{equation*}
&lt;/div&gt;
&lt;div class="math"&gt;
\begin{equation*}
IDF(t) = log_e(\frac{quantidade\ total\ de\ textos}{numero\ de\ textos\ em\ que\ t\ aparece})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Recomendo bastante a wikipédia em inglês, há bastante exemplos de cálculos variantes: &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"&gt;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Logicamente há inconsistências, afinal apenas a frequência não alcança o uso das palavras, não indica necessariamente as mais significativas se uma pessoa em vez de fazer referências a uma palavra ficar repetindo a mesma coisa o tempo todo. ex.:&lt;/p&gt;
&lt;!--  --&gt;
&lt;blockquote&gt;
&lt;p&gt;"há filmes bons, ruins e medianos, mas o filme em questão é o pior de todos, o filme é tão chato e cansativo que todos dormem assistindo os primeiros minutos do filme"&lt;/p&gt;
&lt;p&gt;"há filmes bons, ruins e medianos, mas este em questão é o pior de todos, tão chato e cansativo que todos dormem aos primeiros minutos"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;É bem claro que apesar do sentido do texto ser o mesmo, a importância dada à palavra "filme" seria diferente. E de fato, o TF-IDF funciona melhor para textos que seguem as regras de coesão e coerência, então vamos usar publicações da wikipédia.&lt;/p&gt;
&lt;p&gt;Apesar do cálculo ser bastante simples, vou preferir usar o sklearn pois neste caso o mais importante é ter uma ideia geral sobre um recurso básico e servir como uma introdução básica sobre NLP, especialmente sobre vertorização de textos&lt;/p&gt;
&lt;div class="section" id="tf-idf"&gt;
&lt;h2&gt;TF-IDF&lt;/h2&gt;
&lt;p&gt;Como quase tudo no sklearn...&lt;/p&gt;
&lt;table class="codetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-1"&gt; 1&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-2"&gt; 2&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-3"&gt; 3&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-4"&gt; 4&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-5"&gt; 5&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-6"&gt; 6&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-7"&gt; 7&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-8"&gt; 8&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-9"&gt; 9&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-10"&gt;10&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-11"&gt;11&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-12"&gt;12&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-13"&gt;13&lt;/a&gt;
&lt;a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/#rest_code_7cb1fdbb029842fa809f3b6af21acd22-14"&gt;14&lt;/a&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code python"&gt;&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-1"&gt;&lt;/a&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wikipedia&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-2"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nltk.corpus&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction.text&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;stopw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"portuguese"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;\
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-6"&gt;&lt;/a&gt;        &lt;span class="n"&gt;stopwords&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"english"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;wikipedia&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_lang&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"pt"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wikipedia&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Alan_Turing"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TfidfVectorizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stop_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;stopw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitlines&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;a name="rest_code_7cb1fdbb029842fa809f3b6af21acd22-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Na penúltima linha usei o &lt;cite&gt;splitlines&lt;/cite&gt; para dividir o texto em parágrafos, assim podemos posteriormente coletar informações sobre os termos relevantes para cada parágrafo, mas admito esta forma ser demasiadamente simplista pois neste caso acabo considerando subtítulos como parágrafos.&lt;/p&gt;
&lt;p&gt;Internamente, o objeto que criamos, durante o treinamento, armazena um dicionário com as palavras e um "id", vamos usar isso para converter os termos:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_aaf91543a0d342dcac0dc2d7b53ad8d2-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
&lt;a name="rest_code_aaf91543a0d342dcac0dc2d7b53ad8d2-2"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="n"&gt;x664&lt;/span&gt; &lt;span class="n"&gt;sparse&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="s1"&gt;'&amp;lt;class '&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="s1"&gt;'&amp;gt;'&lt;/span&gt;
&lt;a name="rest_code_aaf91543a0d342dcac0dc2d7b53ad8d2-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="mi"&gt;862&lt;/span&gt; &lt;span class="n"&gt;stored&lt;/span&gt; &lt;span class="n"&gt;elements&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Compressed&lt;/span&gt; &lt;span class="n"&gt;Sparse&lt;/span&gt; &lt;span class="n"&gt;Row&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;A matriz esparsa tem diversas vantagens quando tratamos com longos arrays rechados de zeros, talvez o produto principal nessa implementação seja exatamente essa matriz que indica em cada parágrafo quais os termos presentes e a sua frequência, que é o ponto principal do TF-IDF.&lt;/p&gt;
&lt;img alt="visualização da matriz resultante" src="http://demacdolincoln.github.io/anotacoes-nlp/posts/images/lsa.png"&gt;
&lt;p&gt;E é exatamente sobre essa matriz que chegamos no LSA (Latent Semantic Analysis), mas antes vamos ver quais as palavras mais relevantes do primeiro parágrafo:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;ft_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfidf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_feature_names&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-2"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;top_tfidf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toarray&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-3"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;top_tfidf&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-4"&gt;&lt;/a&gt;        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ft_name&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;computação&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;cheshire&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;junho&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;ciência&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;influente&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;algoritmo&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;east&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;lógico&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;desenvolvimento&lt;/span&gt;
&lt;a name="rest_code_93175e2afb5b462d871d714b20642d30-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;desempenhando&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;O ft_name é a lista de termos que irá converter para string a posição do termo indicada quando ordenamos o array comtendo o valor calculado para cada termo devolvendo as respectivas posições.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lsa"&gt;
&lt;h2&gt;LSA&lt;/h2&gt;
&lt;p&gt;O LSA é nada mais que usar o &lt;a class="reference external" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/svd-vs-pca"&gt;SVD&lt;/a&gt; mas em vez de diminuir as dimensões vamos manter o tamanho da matriz:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-1"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-2"&gt;&lt;/a&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;664&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-4"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;lsa&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TruncatedSVD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-5"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;lsa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;TruncatedSVD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;algorithm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'randomized'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_components&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_8576c53e09a1446d9c200ae950318432-7"&gt;&lt;/a&gt;   &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tol&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;O real poder do LSA vem desse tratamento dado à matriz formada a partir do TF-IDF, o código abaixo indica as palavras mais relevantes para cada parágrafo:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;comp&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lsa&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;components_&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;terms_in_comp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ft_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;comp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;sorted_terms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;terms_in_comp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-4"&gt;&lt;/a&gt;                          &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"paragrafo: {i}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sorted_terms&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-8"&gt;&lt;/a&gt;        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;a name="rest_code_5eddfef9e5e04ca2a5e679e9a0e194e3-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Pegando apenas o parágrafo 0, o resultado que temos é:&lt;/p&gt;
&lt;table class="docutils field-list" frame="void" rules="none"&gt;
&lt;col class="field-name"&gt;
&lt;col class="field-body"&gt;
&lt;tbody valign="top"&gt;
&lt;tr class="field"&gt;&lt;th class="field-name"&gt;paragrafo 0:&lt;/th&gt;&lt;td class="field-body"&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;turing&lt;/li&gt;
&lt;li&gt;máquina&lt;/li&gt;
&lt;li&gt;alan&lt;/li&gt;
&lt;li&gt;prêmio&lt;/li&gt;
&lt;li&gt;memorial&lt;/li&gt;
&lt;li&gt;guerra&lt;/li&gt;
&lt;li&gt;enigma&lt;/li&gt;
&lt;li&gt;bletchley&lt;/li&gt;
&lt;li&gt;park&lt;/li&gt;
&lt;li&gt;computação&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="off-topic"&gt;
&lt;h2&gt;off-topic&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;E para gerar estatísticas de relevância de um texto inteiro, basta não dividir em parágrafos&lt;/li&gt;
&lt;li&gt;E para gerarmos aquele bag of words que está na moda temos algumas opções, dependendo do caso aplicamos só o &lt;strong&gt;TF&lt;/strong&gt; para gerar um ranking, para outros casos o &lt;strong&gt;TF-IDF&lt;/strong&gt; funciona melhor, especialmente quando juntamos vários textos como uma análise geral de várias páginas de blogs, o LSA tende a ser melhor em usos mais específicos porém nada impede de usa-lo para gerar o ranking de termos para um livro, por exemplo.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="admonition note"&gt;
&lt;p class="first admonition-title"&gt;Nota&lt;/p&gt;
&lt;p class="last"&gt;notebook usado: &lt;a class="reference external" href="http://nbviewer.jupyter.org/github/demacdolincoln/anotacoes-nlp/blob/src/files/estatistica-tf-idf-e-lsa.ipynb"&gt;link para o nbviewer&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>utils</category><guid>http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/estatistica-tf-idf-e-lsa/</guid><pubDate>Fri, 07 Dec 2018 04:47:59 GMT</pubDate></item></channel></rss>