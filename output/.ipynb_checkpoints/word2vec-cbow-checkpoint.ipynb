{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(10, 8)\n",
    "plt.style.use(['dark_background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "corpus_text = pickle.load(\n",
    "    open(\"corpus_text.pickle\", \"rb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id, id2word = {}, {}\n",
    "\n",
    "uniques = set()\n",
    "for words in corpus_text:\n",
    "    for w in words:\n",
    "        uniques.add(w)\n",
    "\n",
    "count_id = 0\n",
    "for word in uniques:\n",
    "    word2id[word] = count_id\n",
    "    id2word[count_id] = word\n",
    "    count_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resultou'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniques), len(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 2\n",
    "pair_ids = []\n",
    "\n",
    "text_size = len(corpus_text)\n",
    "\n",
    "corpus_text = np.array(corpus_text)\n",
    "mask = np.array([i for i in range(-window, window+1) if i is not 0])\n",
    "\n",
    "for paragraph in corpus_text:\n",
    "    paragraph = np.array(paragraph)\n",
    "    text_size = len(paragraph)\n",
    "\n",
    "    for center_word in range(window, text_size-window):\n",
    "        center_word_id = word2id[paragraph[center_word]]\n",
    "        context_words = [word2id[i] for i in paragraph[mask + center_word]]\n",
    "\n",
    "        pair_ids.append([context_words, center_word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|contexto | central | contexto | central |\n",
       "|--|--|--|--|\n",
       "|[525, 134, 175, 608] | 18 | ['sobre', 'base', 'morfogênese', 'previu'] | química|\n",
       "|[134, 18, 608, 282] | 175 | ['base', 'química', 'previu', 'reações'] | morfogênese|\n",
       "|[18, 175, 282, 441] | 608 | ['química', 'morfogênese', 'reações', 'químicas'] | previu|\n",
       "|[175, 608, 441, 36] | 282 | ['morfogênese', 'previu', 'químicas', 'oscilantes'] | reações|\n",
       "|[608, 282, 36, 556] | 441 | ['previu', 'reações', 'oscilantes', 'reação'] | químicas|\n",
       "|[282, 441, 556, 501] | 36 | ['reações', 'químicas', 'reação', 'belousov'] | oscilantes|\n",
       "|[441, 36, 501, 148] | 556 | ['químicas', 'oscilantes', 'belousov', 'zhabotinsky'] | reação|\n",
       "|[36, 556, 148, 531] | 501 | ['oscilantes', 'reação', 'zhabotinsky', 'observadas'] | belousov|\n",
       "|[556, 501, 531, 78] | 148 | ['reação', 'belousov', 'observadas', 'primeira'] | zhabotinsky|\n",
       "|[501, 148, 78, 54] | 531 | ['belousov', 'zhabotinsky', 'primeira', 'vez'] | observadas|\n",
       "|[148, 531, 54, 237] | 78 | ['zhabotinsky', 'observadas', 'vez', 'década'] | primeira|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_out = \"|contexto | central | contexto | central |\\n|--|--|--|--|\\n\"\n",
    "for i in range(95, 106):\n",
    "    w0, w1 = pair_ids[i]\n",
    "    ex_out += f\"|{w0} | {w1} | {[id2word[w] for w in w0]} | {id2word[w1]}|\\n\"\n",
    "\n",
    "Markdown(ex_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, emb_size)\n",
    "        \n",
    "        self.linear0 =  torch.nn.Linear(2*emb_size*context_size, 512)\n",
    "        self.linear1 = torch.nn.Linear(512, vocab_size)\n",
    "\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embeddings(x).view(1, -1)\n",
    "\n",
    "        out = self.linear0(out)\n",
    "        out = self.linear1(out)\n",
    "        \n",
    "        out = self.log_softmax(out)\n",
    "        return out\n",
    "    \n",
    "    def get_word_emb(self, word_id):\n",
    "        word = torch.LongTensor([word_id])\n",
    "        return self.embeddings(word).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = CBOW(len(uniques), 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acidental'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_data = torch.LongTensor(pair_ids[100][0])\n",
    "target_data = torch.LongTensor(pair_ids[100][1])\n",
    "res = cbow(teste_data).argmax().item()\n",
    "id2word[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  - 6.144\n",
      "20 - 3.571\n",
      "40 - 0.209\n",
      "60 - 0.198\n"
     ]
    }
   ],
   "source": [
    "nll_loss = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(cbow.parameters(), lr=0.001)\n",
    "\n",
    "indexes = np.arange(len(pair_ids))\n",
    "losses = []\n",
    "for epoch in range(101):\n",
    "    np.random.shuffle(indexes)\n",
    "    for index in indexes:\n",
    "        context, target = pair_ids[index]\n",
    "        optimizer.zero_grad()\n",
    "        cbow.zero_grad()\n",
    "        \n",
    "        X = torch.LongTensor(context)\n",
    "        Y = torch.LongTensor([target])\n",
    "        out_prob = cbow(X)\n",
    "        loss = nll_loss(out_prob, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    if epoch %20 == 0:\n",
    "        print(f\"{epoch:<2} - {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure()\n",
    "ax = fig.gca()\n",
    "ax.plot(losses)\n",
    "savefig(\"../images/word2vec-cbow-loss.png\", dpi=\"figure\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pos = 28\n",
    "teste_data = torch.LongTensor(pair_ids[_pos][0])\n",
    "target_data = torch.LongTensor(pair_ids[_pos][1])\n",
    "res = cbow(teste_data).argmax().item()\n",
    "print(f\"data:{[id2word[i] for i in pair_ids[_pos][0]]} | target: {id2word[pair_ids[_pos][1]]}\")\n",
    "print(f\"{id2word[res]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow.get_word_emb(_pos).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.DataFrame({\n",
    "    \"words\":list(uniques),\n",
    "    \"id\": [word2id[i] for i in uniques],\n",
    "    \"emb\": [cbow.get_word_emb(word2id[i]).detach().numpy()[0] for i in uniques],\n",
    "    \"x\" : [0]*len(uniques),\n",
    "    \"y\": [0]*len(uniques)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "a = np.array([cbow.get_word_emb(word2id[i]).detach().numpy()[0] for i in uniques],)\n",
    "XY = pca.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf[\"x\"] = XY[:, 0]\n",
    "dataf[\"y\"] = XY[:, 1]\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.themes.enable('opaque')\n",
    "base = alt.Chart(dataf).properties(\n",
    "        width=500,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "base.mark_circle(size=180).encode(x=\"x\", y=\"y\", tooltip=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn_eucl_cos import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word2id[\"turing\"]\n",
    "\n",
    "matrix = np.array(dataf.values[:, 3:5], dtype=np.float64)\n",
    "result_pos, result_values = knn(matrix, pos=w)\n",
    "\n",
    "for i, j in zip(result_pos, result_values):\n",
    "    print(id2word[i], f\"{j:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
