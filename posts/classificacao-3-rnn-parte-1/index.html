<!DOCTYPE html>
<html prefix="" lang="pt_br">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Classificação 3: RNN parte 1 | Anotações sobre NLP</title>
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/dark.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Share+Tech+Mono" rel="stylesheet">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><script src="https://cdn.jsdelivr.net/npm/vega@4.4.0"></script><script src="https://cdn.jsdelivr.net/npm/vega-lite@2.6.0"></script><script src="https://cdn.jsdelivr.net/npm/vega-embed@3.24.2"></script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/languages/python.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/languages/julia.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script><meta name="author" content="Lincoln de Macêdo">
<link rel="prev" href="../resumos-0-pagerank/" title="Resumos 0: PageRank" type="text/html">
<link rel="next" href="../classificacao-4-rnn-parte-2-%2B-convolucao/" title="Classificação 4: RNN parte 2 (+ convolução)" type="text/html">
<meta property="og:site_name" content="Anotações sobre NLP">
<meta property="og:title" content="Classificação 3: RNN parte 1">
<meta property="og:url" content="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/">
<meta property="og:description" content="Nota
os códigos estão aqui: https://github.com/demacdolincoln/test-sentiment_analysis

Nste primeiro experimento com redes neurais recorrentes, vamos apenas analisar o efeito da própria recorrência co">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-01-20T18:08:26-03:00">
<meta property="article:tag" content="gru">
<meta property="article:tag" content="lstm">
<meta property="article:tag" content="rnn">
</head>
<body class="hack dark">

<a href="#content" class="sr-only sr-only-focusable">Pular para o conteúdo principal</a>
    <div id="container">
         
    <header id="header"><h1 id="brand"><a href="http://demacdolincoln.github.io/anotacoes-nlp/posts/" title="Anotações sobre NLP" rel="home">

        <span id="blog-title">Anotações sobre NLP</span>
    </a></h1>

        

        
    <nav id="menu"><ul>
<li><a href="../../archive.html">Arquivo</a></li>
                <li><a href="../../categories/">Etiqueta</a></li>
                <li><a href="../../rss.xml">Feed RSS</a></li>

    

    
    
    </ul></nav></header><main id="content"><article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Classificação 3: RNN parte 1</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Lincoln de Macêdo
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2019-01-20T18:08:26-03:00" itemprop="datePublished" title="2019-01-20 18:08">2019-01-20 18:08</time></a>
            </p>
                <p class="commentline">
        
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/classificacao-3-rnn-parte-1.html">Comments</a>


            
        </p>
<p class="sourceline"><a href="index.rst" class="sourcelink">Código</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="admonition note">
<p class="first admonition-title">Nota</p>
<p class="last">os códigos estão aqui: <a class="reference external" href="https://github.com/demacdolincoln/test-sentiment_analysis">https://github.com/demacdolincoln/test-sentiment_analysis</a></p>
</div>
<p>Nste primeiro experimento com redes neurais recorrentes, vamos apenas analisar o efeito da própria recorrência com o LSTM e GRU. Preliminarmente é preciso compreender alguns aspectos:</p>
<ol class="arabic simple">
<li>O que faremos com o skip-gram treinado pelo Gensim?</li>
<li>Em quê o LSTM ou o GRU poderão influenciar?</li>
<li>Se a entrada tem tamanho variável, como internamente fica a rede neural?</li>
</ol>
<p>Antes de chegar a essas explicações, essa é a classe que contém nossa rede neural:</p>
<table class="codetable"><tr>
<td class="linenos"><div class="linenodiv"><pre><a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-1"> 1</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-2"> 2</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-3"> 3</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-4"> 4</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-5"> 5</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-6"> 6</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-7"> 7</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-8"> 8</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-9"> 9</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-10">10</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-11">11</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-12">12</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-13">13</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-14">14</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-15">15</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-16">16</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-17">17</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-18">18</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-19">19</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-20">20</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-21">21</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-22">22</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-23">23</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-24">24</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-25">25</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-26">26</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-27">27</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-28">28</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-29">29</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-30">30</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-31">31</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-32">32</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-33">33</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-34">34</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-35">35</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-36">36</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-37">37</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-38">38</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-39">39</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-40">40</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-41">41</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-42">42</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-43">43</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-44">44</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-45">45</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-46">46</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-47">47</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-48">48</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-49">49</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-50">50</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-51">51</a>
<a href="#rest_code_edc7571fa314496bb1beb8a61c805a6f-52">52</a></pre></div></td>
<td class="code"><pre class="code python"><a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-1"></a><span class="k">class</span> <span class="nc">RNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">RNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-4"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-10"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-13"></a>            <span class="s2">"weight"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-14"></a>        <span class="p">})</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-15"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-16"></a>        <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="s2">"gru"</span><span class="p">:</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-17"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">recurrence</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-18"></a>        <span class="k">elif</span> <span class="n">mode</span> <span class="ow">is</span> <span class="s2">"lstm"</span><span class="p">:</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-19"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">recurrence</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-20"></a>        <span class="k">else</span><span class="p">:</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-21"></a>            <span class="k">raise</span> <span class="s2">"escolha entre gru e lstm apenas"</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-22"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-23"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">hidden</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">hidden</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-24"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">hidden</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span> <span class="n">hidden</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-25"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-26"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-27"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inpt</span><span class="p">):</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-28"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-29"></a>        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_hidden</span><span class="p">(</span><span class="n">inpt</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-30"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-31"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recurrence</span><span class="p">(</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-32"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">inpt</span><span class="p">),</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-33"></a>            <span class="n">hidden</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-34"></a>        <span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-35"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-36"></a>        <span class="n">space</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-37"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-38"></a>        <span class="n">space</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">x</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-39"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">space</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-40"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-41"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-42"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-43"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-44"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-45"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-46"></a>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-47"></a>    <span class="k">def</span> <span class="nf">_init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-48"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">"lstm"</span><span class="p">:</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-49"></a>            <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-50"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-51"></a>        <span class="k">else</span><span class="p">:</span>
<a name="rest_code_edc7571fa314496bb1beb8a61c805a6f-52"></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</pre></td>
</tr></table>
<div class="section" id="o-que-faremos-com-o-skip-gram-treinado-pelo-gensim">
<h2>1. O que faremos com o skip-gram treinado pelo Gensim?</h2>
<p>A camada incorporada tem uma dupla função: converter a entrada (array de inteiros e de tamanho variável) em uma matriz de largura fixa, útil à célula que cuidará da recorrência, e aplicar o skip-gram, por isso ela precisa ter as seguintes dimensões [tamanho do vocabulario x dimensões do skip-gram], O que é devolvido por esta camada é uma matriz no formato [quantidade de palavras x dimensões do skip-gram].</p>
<pre class="code python"><a name="rest_code_74c5992f789a45a59200b572424a91af-1"></a><span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<a name="rest_code_74c5992f789a45a59200b572424a91af-2"></a><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span>
<a name="rest_code_74c5992f789a45a59200b572424a91af-3"></a>    <span class="s2">"weight"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>
<a name="rest_code_74c5992f789a45a59200b572424a91af-4"></a><span class="p">})</span>
</pre>
<p>Outro fator importante que precisa ser mencionado é que esta camada também está sujeita ao treinamento da rede neural, ou seja, mantendo desse modo como está, estamos aplicando uma transferência neural, ou seja utilizando uma rede já treinada (no caso skip-gram) e continuando seu treinamento aplicado a uma outra situação, cujo treinamento neste novo contexto tende a ter um ponto de partida com maior precisão, esta é a idéia por trás da escolha de manter o treinamento ativo nesta camada, fazer com que o conteúdo aprendido no treinamento feito pelo Gensim vá se adaptando ao contexto da análise de sentimento segundo o dataset utilizado.</p>
</div>
<div class="section" id="em-que-o-lstm-ou-o-gru-poderao-influenciar">
<h2>2. Em quê o LSTM ou o GRU poderão influenciar?</h2>
<p>Em sua estrutura, a recorrêncida da RNN se resume a uma camada oculta, uma célula de recorrência que trata do gerenciamento de memória e a entrada, olhando com atenção, a célula fará basicamente é alterar os pesos da entrada de acordo com a camada oculta, que serve como uma memória, indicando o que valorizar ou não na etapa seguinte da execução da rede neural.</p>
<p>Traduzindo para o contexto da entrada conter a posição de cada palavra num hiperplano de acordo com o valor semântico expresso pelo uso demonstrado no dataset, isso quer dizer que será feito mais um ajuste sobre o skip-gram, na prática esse pós processamento vai indicar a importãncia de cada dimensão para cada palavra, potencializando o viés indicado pelo treinamento do skip-gram.</p>
<p>No PyTorch temos GRU e GRUCell, e LSTM e LSTMCell, a diferença é que usando simpelsmente GRU ou LSTM estamos inserindo uma pequena rede neural com a célula indicada no nome, podemos variar a quantidade de camadas lineares e definir uma taca pra o dropout, etc, mas se usarmos GRUCell ou LSTMCell teremos apenas a célula, no experimento feito, escolhi a 1ª opção pois não custava nada para mim definir logo o dropout em vez de definir ele em algum outro ponto.</p>
<p>Como este é um simples teste para ver o impacto da recorrência, resolvi manter apenas uma memória de curto prazo (reicinializando a cada novo uso da rede neural) para mostrar que mesmo com um uso mínimo as diferenças já são notáveis.</p>
</div>
<div class="section" id="se-a-entrada-tem-tamanho-variavel-como-internamente-fica-a-rede-neural">
<h2>3. Se a entrada tem tamanho variável, como internamente fica a rede neural?</h2>
<p>Em algum momento precisaremos de um tamanho fixo para passar pelas funções lineares, para o experimento atual apenas concatenei a matriz devolvida pelo GRU/LSTM, queria testar nas condições mais adversas, no próximo post aplicarei nesta etapa da execução tanto a convolução 1d quanto a convolução 2d, mas não há como fugir do tamanho fixo em algum momento neste caso, então a regra que usamos no post anterior de considerar o caso com maior quantidade de palavras vale aqui também.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top"><tr class="field">
<th class="field-name">obs:</th>
<td class="field-body">um dos problemas do tamanho variável da entrada está no DataLoader do pytorch, ele lança um erro quando definimos um batch_size que nos deixe confortáveis, para trabalhar com dados em lotes ele exige tamanho fixo, de modo que só nos resta ler 1 item do dataset por vez, deixando o processo muito lento já que a cada item lido será aplicada uma etapa do treinamento, vamos ver a evolução mais rápida considerando as épocas mas a quantidade de vezes que os pesos foram atualizados correspondem a $n_epocas * n_items$</td>
</tr></tbody>
</table>
</div>
<div class="section" id="conclusoes">
<h2>Conclusões</h2>
<img alt="/images/classification_gru_ltsm.png" src="../../images/classification_gru_ltsm.png"><p>É notável e incrível a diferença do uso de redes recorrentes para lidar com linguagem, a grande diferença está no foco da recorrência: enquanto habitualmente ajustamos pesos para classificação, aqui transformamos os valores de entrada e diferentemente da convolução, não espalhamos informações nem produzimos matrizes ou arrays equivalente mas ajustamos a entrada de modo a se adequar melhor ao contexto do treinamenhto, e o melhor de tudo: sabendo lidar com sequências em nível mais abstrato do que apenas arrays e matrizes, o contexto envolta da ordem que as palavras são usadas nas frases tem relevância para a recorrência, e mesmo aplicando tão minimamente e de forma tão pouco eficiente neste exemplo, o resultado já superou largamente o uso de redes convolucionais demonstradas na anotação anterior.</p>
<p>No próximo post vou misturar as coisas, aplicando a recorreência, depois convlução (1d e 2d), e por último camadas lineares, assim espero concluir os modelos temporariamente e fazer uma análise geral sobre o que os métodos apresentados ao longo dessas anotações sobre classificação influenciam os resultados.</p>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/gru/" rel="tag">gru</a></li>
            <li><a class="tag p-category" href="../../categories/lstm/" rel="tag">lstm</a></li>
            <li><a class="tag p-category" href="../../categories/rnn/" rel="tag">rnn</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../resumos-0-pagerank/" rel="prev" title="Resumos 0: PageRank">Post anterior</a>
            </li>
            <li class="next">
                <a href="../classificacao-4-rnn-parte-2-%2B-convolucao/" rel="next" title="Classificação 4: RNN parte 2 (+ convolução)">Próximo post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comentários</h2>
        
        
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="demacdolincoln",
            disqus_url="http://demacdolincoln.github.io/anotacoes-nlp/posts/posts/classificacao-3-rnn-parte-1/",
        disqus_title="Classifica\u00e7\u00e3o 3: RNN parte 1",
        disqus_identifier="cache/posts/classificacao-3-rnn-parte-1.html",
        disqus_config = function () {
            this.language = "pt_br";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="demacdolincoln";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script></main><footer id="footer"><p>Contents © 2019         <a href="mailto:demacdolincoln@gmail.com">Lincoln de Macêdo</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer>
</div>
    
    

    
    
    
</body>
</html>
