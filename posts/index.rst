.. title: README
.. slug: index
.. date: 2018-12-06 02:46:15 UTC-03:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text

Pretendo fazer uma longa série de posts sobre NLP, não sou especialista nisso e podemos considerar os posts mais como anotações de estudo do que tutoriais ou manuais. O Índice abaixo será atualizado à medida que eu for publicando novos conteúdos, a idéia é seguir o andamento histórico de cada parte, na 1ª parte começaremos com o tf-idf para depois seguirmos para o word2vec e glove:


* parte 1: vetorização
    * `estatística: tf-idf <link://filename/posts/estatistica-tf-idf-e-lsa.rst>`_
    * `word2vec 1: introdução <link://filename/posts/word2vec-1-introducao.rst>`_
    * `word2vec 2: cbow <link://filename/posts/word2vec-2-cbow.rst>`_
    * `word2vec 3: skip-gram <link://filename/posts/word2vec-3-skip-gram.rst>`_
    * *glove*
    * `seq2seq: introdução <link://filename/posts/seq2seq-introducao.rst>`_
    * *notas finais e comparações entre métodos*

* parte 2: classificação
    * `classificação 1: introdução <link://filename/posts/classificacao-1.rst>`_
    * `classificacao 2: CNN <link://filename/posts/classificacao-2-cnn.rst>`_

* parte 3: modelagem
    * `resumos 0: textrank <link://filename/posts/resumos-0-textrank>`_
    * `seq2seq: implementação <link://filename/posts/seq2seq-implementacao.rst>`_

* utils
    * `Pré-processamento de textos <link://filename/posts/pre-processamento-de-textos.rst>`_. (*muito importante*)
    * `SVD vs PCA <link://filename/posts/svd-vs-pca.rst>`_
    * `distância euclidiana vs similaridade de cossenos <link://filename/posts/distancia-euclidiama-vs-similaridade-de-cossenos.rst>`_
    * `GRU e LSTM <link://filename/posts/gru-e-lstm.rst>`_

Obs1.: O pré-processamento é a etapa inicial de praticamente todos os conteúdos aqui escritos, é realmente muito importante, por isso antes de partir para qualquer outro conteúdo, leia ele primeiro.

Obs2.: O que estiver em itálico é que ainda não escrevi mas devo fazer ao longo dessas semanas. As partes 2 e 3 possivelmente serão sobre classificação de textos e modelagem com cadeias de markov e RNN.
